{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 07: M1/S2 - Unsupervised Anomaly Detection (Sentence Level)\n",
    "\n",
    "**C√≠l:** Detekovat subjektivitu (L1) jako anom√°lii v≈Øƒçi neutralitƒõ (L0) na √∫rovni cel√Ωch vƒõt.\n",
    "**Metoda:** Mahalanobisova vzd√°lenost (Unsupervised).\n",
    "**Hypot√©za:** Subjektivn√≠ vƒõty se s√©manticky li≈°√≠ od neutr√°ln√≠ch, tak≈æe budou m√≠t v embedding prostoru velkou vzd√°lenost od centroidu neutrality.\n",
    "\n",
    "**Sc√©n√°≈ôe:**\n",
    "* **S2a - Baseline:** Tr√©nink pouze na Target L0 vƒõt√°ch (Gold).\n",
    "* **S2c - Robustness (Context):** Tr√©nink na Target L0 + Context L0 vƒõt√°ch.\n",
    "\n",
    "**Pooling:**\n",
    "* Porovn√°me **Mean** vs **[CLS]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "from itables import show\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Auto-reload modules for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Add src to path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "# Vlastn√≠ moduly\n",
    "import config\n",
    "import data_splitting\n",
    "import models\n",
    "import evaluation\n",
    "import visualization\n",
    "\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Vizualizace\n",
    "visualization.setup_style()\n",
    "\n",
    "print(f\"‚úÖ Setup complete. Results dir: {config.RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "datacheck",
   "metadata": {},
   "source": [
    "## 2. Data Check\n",
    "V Unsupervised learningu n√°s zaj√≠m√° hlavnƒõ poƒçet **Neutr√°ln√≠ch (L0)** vƒõt v tr√©ninku. Model se uƒç√≠ jen z nich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS_TO_CHECK = ['baseline', 'robustness']\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"üìä DATA CHECK REPORT (M1/S2 - Unsupervised)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for sc in SCENARIOS_TO_CHECK:\n",
    "    print(f\"\\nüîπ SC√âN√Å≈ò: {sc.upper()}\")\n",
    "    try:\n",
    "        # Naƒçteme data (Mean pooling)\n",
    "        data = data_splitting.get_train_val_test_splits(\n",
    "            scenario=sc,\n",
    "            level='sentence',\n",
    "            pooling='mean',\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Pro M1 n√°s v TRAIN zaj√≠m√° jen L0 (zbytek se zahod√≠)\n",
    "        n_train_total = len(data['y_train'])\n",
    "        n_train_L0 = sum(data['y_train'] == 0)\n",
    "        n_train_L1 = sum(data['y_train'] == 1)\n",
    "        \n",
    "        print(f\"   TRAIN (Total): {n_train_total}\")\n",
    "        print(f\"   üëâ Pou≈æiteln√© pro M1 (L0): {n_train_L0} (Model se uƒç√≠ jen toto)\")\n",
    "        print(f\"   üëâ Ignorovan√© v Train (L1): {n_train_L1}\")\n",
    "        print(f\"   TEST (Total): {len(data['y_test'])} (L0: {sum(data['y_test']==0)}, L1: {sum(data['y_test']==1)})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Chyba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experiments",
   "metadata": {},
   "source": [
    "## 3. Experiment Loop\n",
    "Tr√©nujeme **Mahalanobis** detektor.\n",
    "Iterujeme p≈ôes:\n",
    "1.  **Pooling:** `mean` vs `cls`\n",
    "2.  **Sc√©n√°≈ôe:** `baseline` (m√°lo dat) vs `robustness` (hodnƒõ L0 dat z kontextu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = config.RESULTS_DIR / \"M1_S2_experiment_results_v1.csv\"\n",
    "\n",
    "SCENARIOS = [\n",
    "    {'id': 'S2a', 'name': 'Baseline (Target L0)',    'scenario': 'baseline'},\n",
    "    {'id': 'S2c', 'name': 'Robustness (Target+Ctx)', 'scenario': 'robustness'}\n",
    "]\n",
    "\n",
    "POOLING_METHODS = ['mean', 'cls']\n",
    "MODEL_NAME = 'Mahalanobis'\n",
    "\n",
    "results = []\n",
    "best_auprc = 0.0\n",
    "best_run = None\n",
    "\n",
    "print(f\"üöÄ STARTING M1/S2 EXPERIMENTS...\")\n",
    "print(f\"üíæ Results path: {RESULTS_PATH}\")\n",
    "\n",
    "for pooling in POOLING_METHODS:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"üåä POOLING METHOD: {pooling.upper()}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    \n",
    "    for exp in SCENARIOS:\n",
    "        print(f\"\\n   üß™ SCENARIO: {exp['id']} - {exp['name']}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Naƒçten√≠ dat\n",
    "            data = data_splitting.get_train_val_test_splits(\n",
    "                scenario=exp['scenario'],\n",
    "                level='sentence',\n",
    "                pooling=pooling,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # 2. Filtrace pro Unsupervised (Train = pouze L0)\n",
    "            X_train = data['X_train'][data['y_train'] == 0]\n",
    "            \n",
    "            # Val/Test nech√°v√°me kompletn√≠ (pro ovƒõ≈ôen√≠ detekce)\n",
    "            X_val, y_val = data['X_val'], data['y_val']\n",
    "            X_test, y_test = data['X_test'], data['y_test']\n",
    "            \n",
    "            print(f\"      üìä Train L0 Size: {X_train.shape[0]} samples\")\n",
    "            \n",
    "            # Kontrola: M√°me dost dat?\n",
    "            # Mahalanobis pot≈ôebuje v√≠ce vzork≈Ø ne≈æ dimenz√≠ (768), jinak sel≈æe (Singular Matrix)\n",
    "            # Pokud pou≈æijeme PCA, sn√≠≈æ√≠me dimenzi.\n",
    "            \n",
    "            # 3. Fit Model\n",
    "            # Pou≈æijeme PCA redukci, pokud je m√°lo dat (m√©nƒõ ne≈æ 1000)\n",
    "            n_components = 0.95 if X_train.shape[0] > 50 else 0.90\n",
    "            \n",
    "            # Inicializace Mahalanobise\n",
    "            clf = models.get_unsupervised_model(MODEL_NAME, pca_components=n_components, random_state=42)\n",
    "            clf.fit(X_train)\n",
    "            \n",
    "            # 4. Sk√≥rov√°n√≠ (Anomaly Score)\n",
    "            # Vy≈°≈°√≠ sk√≥re = vƒõt≈°√≠ anom√°lie\n",
    "            s_train = clf.decision_function(X_train)\n",
    "            s_val   = clf.decision_function(X_val)\n",
    "            s_test  = clf.decision_function(X_test)\n",
    "            \n",
    "            # 5. Threshold Tuning (na Val)\n",
    "            threshold, _ = evaluation.find_optimal_threshold(y_val, s_val, metric='f1')\n",
    "            \n",
    "            # 6. Metriky\n",
    "            m_train = evaluation.calculate_metrics(np.zeros(len(s_train)), (s_train > threshold).astype(int), s_train)\n",
    "            m_val   = evaluation.calculate_metrics(y_val, (s_val > threshold).astype(int), s_val)\n",
    "            m_test  = evaluation.calculate_metrics(y_test, (s_test > threshold).astype(int), s_test)\n",
    "            \n",
    "            # Log\n",
    "            res = {\n",
    "                'id': exp['id'],\n",
    "                'scenario': exp['scenario'],\n",
    "                'scenario_name': exp['name'],\n",
    "                'pooling': pooling,\n",
    "                'model': MODEL_NAME,\n",
    "                'pca_dim': clf.pca.n_components_ if hasattr(clf, 'pca') else 768,\n",
    "                'threshold': threshold,\n",
    "                \n",
    "                'test_f1': m_test['f1'], 'test_auprc': m_test['avg_precision'], \n",
    "                'test_roc_auc': m_test['roc_auc'], 'test_prec': m_test['precision'], 'test_rec': m_test['recall']\n",
    "            }\n",
    "            results.append(res)\n",
    "            pd.DataFrame(results).to_csv(RESULTS_PATH, index=False)\n",
    "            print(f\"      ‚úÖ Result: AUPRC={m_test['avg_precision']:.4f}, F1={m_test['f1']:.4f}\")\n",
    "\n",
    "            # Best Run Save\n",
    "            if m_test['avg_precision'] > best_auprc:\n",
    "                best_auprc = m_test['avg_precision']\n",
    "                best_run = {\n",
    "                    'info': res,\n",
    "                    'model': clf,\n",
    "                    'data': data,\n",
    "                    'scores_test': s_test,\n",
    "                    'y_test': y_test,\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All M1/S2 experiments finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results",
   "metadata": {},
   "source": [
    "## 4. Results Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESULTS_PATH.exists():\n",
    "    df_results = pd.read_csv(RESULTS_PATH)\n",
    "    \n",
    "    # Pivot Table\n",
    "    print(\"üìä SROVN√ÅN√ç AUPRC (Pooling x Scenario):\")\n",
    "    pivot = df_results.pivot_table(\n",
    "        values='test_auprc', \n",
    "        index='pooling', \n",
    "        columns='scenario_name',\n",
    "        aggfunc='max'\n",
    "    )\n",
    "    display(pivot.style.background_gradient(cmap='Blues').format(\"{:.4f}\"))\n",
    "    \n",
    "    # Grafy\n",
    "    print(\"\\nüìä GRAFY V√ùSLEDK≈Æ:\")\n",
    "    visualization.plot_pooling_breakdown(df_results, metric='auprc')\n",
    "    visualization.plot_pooling_breakdown(df_results, metric='f1')\n",
    "else:\n",
    "    print(\"≈Ω√°dn√© v√Ωsledky.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deep_dive",
   "metadata": {},
   "source": [
    "## 5. Deep Dive: Winner Analysis\n",
    "Detailn√≠ pohled na nejlep≈°√≠ model (pravdƒõpodobnƒõ Robustness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "winner_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_run:\n",
    "    info = best_run['info']\n",
    "    print(f\"üèÜ WINNER: {info['model']} ({info['scenario_name']})\")\n",
    "    print(f\"üåä Pooling: {info['pooling'].upper()}\")\n",
    "    print(f\"üìâ PCA Dimensions: {info['pca_dim']}\")\n",
    "    print(f\"üìä Test AUPRC: {info['test_auprc']:.4f}\")\n",
    "    \n",
    "    # Predikce\n",
    "    y_test = best_run['y_test']\n",
    "    scores = best_run['scores_test']\n",
    "    thresh = info['threshold']\n",
    "    y_pred = (scores > thresh).astype(int)\n",
    "    \n",
    "    # Vizualizace\n",
    "    visualization.plot_confusion_matrix_heatmap(y_test, y_pred, normalize=True, title=\"Confusion Matrix\")\n",
    "    visualization.plot_pr_curve(y_test, scores, title=\"PR Curve\")\n",
    "    visualization.plot_anomaly_histogram(y_test, scores, threshold=thresh, title=\"Anomaly Score Dist.\")\n",
    "    \n",
    "    # Kvalitativn√≠ anal√Ωza\n",
    "    df_qual = best_run['data']['meta_test'].copy()\n",
    "    df_qual['true'] = y_test\n",
    "    df_qual['pred'] = y_pred\n",
    "    df_qual['score'] = scores\n",
    "    \n",
    "    conds = [\n",
    "        (df_qual.true==1) & (df_qual.pred==1), (df_qual.true==0) & (df_qual.pred==0),\n",
    "        (df_qual.true==0) & (df_qual.pred==1), (df_qual.true==1) & (df_qual.pred==0)\n",
    "    ]\n",
    "    df_qual['category'] = np.select(conds, ['TP', 'TN', 'FP', 'FN'], default='UNKNOWN')\n",
    "    \n",
    "    print(\"\\n‚ùå TOP 5 FP (Fale≈°n√Ω poplach):\")\n",
    "    display(df_qual[df_qual['category'] == 'FP'].sort_values('score', ascending=False).head(5))\n",
    "    \n",
    "    df_qual.to_csv(config.RESULTS_DIR / \"M1_S2_Qualitative.csv\", index=False)\n",
    "else:\n",
    "    print(\"Spus≈• experimenty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
