{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c01442",
   "metadata": {},
   "source": [
    "# 03: M1/S1 - Unsupervised Anomaly Detection (Token Level)\n",
    "\n",
    "**Goal:** Detect subjective words (LJMPNIK) using unsupervised methods (Mahalanobis, Isolation Forest, OCSVM).\n",
    " \n",
    "**Methodology:**\n",
    "1. **Training:** On purely neutral tokens (L0) from `gold` dataset.\n",
    "2. **Validation:** On mixed data (L0 + L1) to find optimal threshold.\n",
    "3. **Testing:** On held-out mixed data (Document-level split).\n",
    " \n",
    "**Note:** Uses new `data_splitting` module to prevent data leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8d57f",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128f6968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration loaded. Device: cpu\n",
      "‚úÖ Setup complete. Data dir: C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itables import show\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Auto-reload modules for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Add src to path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "# Import custom modules\n",
    "import config\n",
    "import data_splitting\n",
    "import models\n",
    "import visualization\n",
    "import experiments\n",
    "import evaluation\n",
    "\n",
    "\n",
    "# Setup visualization style\n",
    "visualization.setup_style()\n",
    "\n",
    "print(f\"‚úÖ Setup complete. Data dir: {config.DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf24556",
   "metadata": {},
   "source": [
    "## 2. Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c76a64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 20:56:57,097 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:57,097 - INFO - üìä Preparing scenario: baseline (token level, aggressive filter)\n",
      "2026-02-03 20:56:57,616 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:57:00,073 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:57:00,131 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:57:00,139 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:57:00,141 - INFO -    Train: 376 docs, 2585 samples\n",
      "2026-02-03 20:57:00,142 - INFO -    Val:   41 docs, 270 samples\n",
      "2026-02-03 20:57:00,143 - INFO -    Test:  103 docs, 741 samples\n",
      "2026-02-03 20:57:00,146 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:57:00,148 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:57:00,152 - INFO -    Train: 2585 samples (L0: 900, L1: 1685)\n",
      "2026-02-03 20:57:00,154 - INFO -    Val:   270 samples (L0: 96, L1: 174)\n",
      "2026-02-03 20:57:00,155 - INFO -    Test:  741 samples (L0: 256, L1: 485)\n",
      "2026-02-03 20:57:00,236 - INFO -    üßπ Purifying Train Set: Removed 1685 anomalies (L1). Kept 900 neutral samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ TRAIN set (Neutral only): (900, 768)\n",
      "üîπ VAL set (Mixed):          (270, 768)\n",
      "üîπ TEST set (Mixed):         (741, 768)\n",
      "‚ö†Ô∏è Anomalies in Train: 0 (Should be 0)\n"
     ]
    }
   ],
   "source": [
    "# Load sample data (Aggressive filter) just to check stats\n",
    "\n",
    "data_sample = data_splitting.get_unsupervised_splits(\n",
    "    scenario='baseline', \n",
    "    level='token', \n",
    "    filter_type='aggressive'\n",
    ")\n",
    "\n",
    "print(f\"üîπ TRAIN set (Neutral only): {data_sample['X_train'].shape}\")\n",
    "print(f\"üîπ VAL set (Mixed):          {data_sample['X_val'].shape}\")\n",
    "print(f\"üîπ TEST set (Mixed):         {data_sample['X_test'].shape}\")\n",
    "\n",
    "# Verify Train contains only L0\n",
    "train_anomalies = data_sample['y_train'].sum()\n",
    "print(f\"‚ö†Ô∏è Anomalies in Train: {train_anomalies} (Should be 0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff57deea",
   "metadata": {},
   "source": [
    "## 3. Experimental Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5eef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Defined 9 scenarios.\n"
     ]
    }
   ],
   "source": [
    "# Define scenarios to run\n",
    "\n",
    "scenarios = []\n",
    "filters = ['aggressive', 'mild', 'none']\n",
    "models_list = ['Mahalanobis', 'IsolationForest', 'OCSVM']\n",
    "\n",
    "for m in models_list:\n",
    "    for f in filters:\n",
    "        scenarios.append({\n",
    "            'model': m,\n",
    "            'filter': f,\n",
    "            'level': 'token' # This notebook is S1 (Token)\n",
    "        })\n",
    "\n",
    "print(f\"üöÄ Defined {len(scenarios)} scenarios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876f3e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running M1 Experiments:   0%|          | 0/9 [00:00<?, ?it/s]2026-02-03 20:56:05,016 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:05,016 - INFO - üìä Preparing scenario: baseline (token level, aggressive filter)\n",
      "2026-02-03 20:56:05,449 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:08,050 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:08,103 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:08,114 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:08,114 - INFO -    Train: 376 docs, 2585 samples\n",
      "2026-02-03 20:56:08,114 - INFO -    Val:   41 docs, 270 samples\n",
      "2026-02-03 20:56:08,114 - INFO -    Test:  103 docs, 741 samples\n",
      "2026-02-03 20:56:08,114 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:08,114 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:08,114 - INFO -    Train: 2585 samples (L0: 900, L1: 1685)\n",
      "2026-02-03 20:56:08,124 - INFO -    Val:   270 samples (L0: 96, L1: 174)\n",
      "2026-02-03 20:56:08,124 - INFO -    Test:  741 samples (L0: 256, L1: 485)\n",
      "2026-02-03 20:56:08,188 - INFO -    üßπ Purifying Train Set: Removed 1685 anomalies (L1). Kept 900 neutral samples.\n",
      "2026-02-03 20:56:08,209 - ERROR - Failed run Mahalanobis / aggressive: 'mahalanobis'\n",
      "Running M1 Experiments:  11%|‚ñà         | 1/9 [00:03<00:25,  3.20s/it]2026-02-03 20:56:08,221 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:08,221 - INFO - üìä Preparing scenario: baseline (token level, mild filter)\n",
      "2026-02-03 20:56:08,702 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:10,839 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:10,904 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:10,916 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:10,919 - INFO -    Train: 376 docs, 2654 samples\n",
      "2026-02-03 20:56:10,919 - INFO -    Val:   41 docs, 278 samples\n",
      "2026-02-03 20:56:10,919 - INFO -    Test:  103 docs, 755 samples\n",
      "2026-02-03 20:56:10,925 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:10,928 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:10,932 - INFO -    Train: 2654 samples (L0: 918, L1: 1736)\n",
      "2026-02-03 20:56:10,934 - INFO -    Val:   278 samples (L0: 97, L1: 181)\n",
      "2026-02-03 20:56:10,941 - INFO -    Test:  755 samples (L0: 260, L1: 495)\n",
      "2026-02-03 20:56:11,045 - INFO -    üßπ Purifying Train Set: Removed 1736 anomalies (L1). Kept 918 neutral samples.\n",
      "2026-02-03 20:56:11,072 - ERROR - Failed run Mahalanobis / mild: 'mahalanobis'\n",
      "Running M1 Experiments:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:06<00:20,  3.00s/it]2026-02-03 20:56:11,072 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:11,077 - INFO - üìä Preparing scenario: baseline (token level, none filter)\n",
      "2026-02-03 20:56:11,767 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:14,472 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:14,493 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:14,503 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:14,503 - INFO -    Train: 376 docs, 4369 samples\n",
      "2026-02-03 20:56:14,503 - INFO -    Val:   41 docs, 454 samples\n",
      "2026-02-03 20:56:14,511 - INFO -    Test:  103 docs, 1246 samples\n",
      "2026-02-03 20:56:14,514 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:14,519 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:14,519 - INFO -    Train: 4369 samples (L0: 1470, L1: 2899)\n",
      "2026-02-03 20:56:14,541 - INFO -    Val:   454 samples (L0: 169, L1: 285)\n",
      "2026-02-03 20:56:14,571 - INFO -    Test:  1246 samples (L0: 413, L1: 833)\n",
      "2026-02-03 20:56:14,695 - INFO -    üßπ Purifying Train Set: Removed 2899 anomalies (L1). Kept 1470 neutral samples.\n",
      "2026-02-03 20:56:14,736 - ERROR - Failed run Mahalanobis / none: 'mahalanobis'\n",
      "Running M1 Experiments:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:09<00:19,  3.30s/it]2026-02-03 20:56:14,738 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:14,738 - INFO - üìä Preparing scenario: baseline (token level, aggressive filter)\n",
      "2026-02-03 20:56:15,234 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:17,461 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:17,522 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:17,536 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:17,536 - INFO -    Train: 376 docs, 2585 samples\n",
      "2026-02-03 20:56:17,536 - INFO -    Val:   41 docs, 270 samples\n",
      "2026-02-03 20:56:17,536 - INFO -    Test:  103 docs, 741 samples\n",
      "2026-02-03 20:56:17,543 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:17,543 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:17,543 - INFO -    Train: 2585 samples (L0: 900, L1: 1685)\n",
      "2026-02-03 20:56:17,543 - INFO -    Val:   270 samples (L0: 96, L1: 174)\n",
      "2026-02-03 20:56:17,552 - INFO -    Test:  741 samples (L0: 256, L1: 485)\n",
      "2026-02-03 20:56:17,626 - INFO -    üßπ Purifying Train Set: Removed 1685 anomalies (L1). Kept 900 neutral samples.\n",
      "2026-02-03 20:56:17,640 - ERROR - Failed run IsolationForest / aggressive: 'n_jobs'\n",
      "Running M1 Experiments:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:12<00:15,  3.15s/it]2026-02-03 20:56:17,650 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:17,650 - INFO - üìä Preparing scenario: baseline (token level, mild filter)\n",
      "2026-02-03 20:56:18,083 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:20,265 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:20,322 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:20,328 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:20,328 - INFO -    Train: 376 docs, 2654 samples\n",
      "2026-02-03 20:56:20,328 - INFO -    Val:   41 docs, 278 samples\n",
      "2026-02-03 20:56:20,338 - INFO -    Test:  103 docs, 755 samples\n",
      "2026-02-03 20:56:20,340 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:20,341 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:20,342 - INFO -    Train: 2654 samples (L0: 918, L1: 1736)\n",
      "2026-02-03 20:56:20,345 - INFO -    Val:   278 samples (L0: 97, L1: 181)\n",
      "2026-02-03 20:56:20,346 - INFO -    Test:  755 samples (L0: 260, L1: 495)\n",
      "2026-02-03 20:56:20,418 - INFO -    üßπ Purifying Train Set: Removed 1736 anomalies (L1). Kept 918 neutral samples.\n",
      "2026-02-03 20:56:20,445 - ERROR - Failed run IsolationForest / mild: 'n_jobs'\n",
      "Running M1 Experiments:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:15<00:12,  3.02s/it]2026-02-03 20:56:20,447 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:20,451 - INFO - üìä Preparing scenario: baseline (token level, none filter)\n",
      "2026-02-03 20:56:21,045 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:23,426 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:23,445 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:23,453 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:23,453 - INFO -    Train: 376 docs, 4369 samples\n",
      "2026-02-03 20:56:23,453 - INFO -    Val:   41 docs, 454 samples\n",
      "2026-02-03 20:56:23,453 - INFO -    Test:  103 docs, 1246 samples\n",
      "2026-02-03 20:56:23,453 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:23,453 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:23,463 - INFO -    Train: 4369 samples (L0: 1470, L1: 2899)\n",
      "2026-02-03 20:56:23,463 - INFO -    Val:   454 samples (L0: 169, L1: 285)\n",
      "2026-02-03 20:56:23,463 - INFO -    Test:  1246 samples (L0: 413, L1: 833)\n",
      "2026-02-03 20:56:23,553 - INFO -    üßπ Purifying Train Set: Removed 2899 anomalies (L1). Kept 1470 neutral samples.\n",
      "2026-02-03 20:56:23,583 - ERROR - Failed run IsolationForest / none: 'n_jobs'\n",
      "Running M1 Experiments:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:18<00:09,  3.06s/it]2026-02-03 20:56:23,583 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:23,589 - INFO - üìä Preparing scenario: baseline (token level, aggressive filter)\n",
      "2026-02-03 20:56:23,997 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:26,057 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:26,111 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:26,119 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:26,121 - INFO -    Train: 376 docs, 2585 samples\n",
      "2026-02-03 20:56:26,122 - INFO -    Val:   41 docs, 270 samples\n",
      "2026-02-03 20:56:26,124 - INFO -    Test:  103 docs, 741 samples\n",
      "2026-02-03 20:56:26,125 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:26,127 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:26,127 - INFO -    Train: 2585 samples (L0: 900, L1: 1685)\n",
      "2026-02-03 20:56:26,130 - INFO -    Val:   270 samples (L0: 96, L1: 174)\n",
      "2026-02-03 20:56:26,130 - INFO -    Test:  741 samples (L0: 256, L1: 485)\n",
      "2026-02-03 20:56:26,200 - INFO -    üßπ Purifying Train Set: Removed 1685 anomalies (L1). Kept 900 neutral samples.\n",
      "Running M1 Experiments:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:21<00:05,  2.97s/it]2026-02-03 20:56:26,365 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:26,365 - INFO - üìä Preparing scenario: baseline (token level, mild filter)\n",
      "2026-02-03 20:56:26,776 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:28,936 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:28,989 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:28,999 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:29,001 - INFO -    Train: 376 docs, 2654 samples\n",
      "2026-02-03 20:56:29,001 - INFO -    Val:   41 docs, 278 samples\n",
      "2026-02-03 20:56:29,001 - INFO -    Test:  103 docs, 755 samples\n",
      "2026-02-03 20:56:29,001 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:29,001 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:29,011 - INFO -    Train: 2654 samples (L0: 918, L1: 1736)\n",
      "2026-02-03 20:56:29,012 - INFO -    Val:   278 samples (L0: 97, L1: 181)\n",
      "2026-02-03 20:56:29,017 - INFO -    Test:  755 samples (L0: 260, L1: 495)\n",
      "2026-02-03 20:56:29,094 - INFO -    üßπ Purifying Train Set: Removed 1736 anomalies (L1). Kept 918 neutral samples.\n",
      "Running M1 Experiments:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:24<00:02,  2.98s/it]2026-02-03 20:56:29,357 - INFO - üîÑ Preparing UNSUPERVISED splits for scenario: baseline (Training strictly on L0)\n",
      "2026-02-03 20:56:29,357 - INFO - üìä Preparing scenario: baseline (token level, none filter)\n",
      "2026-02-03 20:56:29,995 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-03 20:56:32,397 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-03 20:56:32,413 - INFO - Splitting 520 documents: 104 test, 41 val, 375 train\n",
      "2026-02-03 20:56:32,428 - INFO - ‚úÖ Document-level split completed:\n",
      "2026-02-03 20:56:32,430 - INFO -    Train: 376 docs, 4369 samples\n",
      "2026-02-03 20:56:32,430 - INFO -    Val:   41 docs, 454 samples\n",
      "2026-02-03 20:56:32,435 - INFO -    Test:  103 docs, 1246 samples\n",
      "2026-02-03 20:56:32,437 - INFO -    ‚úì No document leakage detected between splits\n",
      "2026-02-03 20:56:32,437 - INFO - ‚úÖ Scenario data prepared:\n",
      "2026-02-03 20:56:32,437 - INFO -    Train: 4369 samples (L0: 1470, L1: 2899)\n",
      "2026-02-03 20:56:32,445 - INFO -    Val:   454 samples (L0: 169, L1: 285)\n",
      "2026-02-03 20:56:32,450 - INFO -    Test:  1246 samples (L0: 413, L1: 833)\n",
      "2026-02-03 20:56:32,534 - INFO -    üßπ Purifying Train Set: Removed 2899 anomalies (L1). Kept 1470 neutral samples.\n",
      "Running M1 Experiments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:28<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Results saved to C:\\Users\\dobes\\Documents\\UniversityCodingProject\\ThesisCoding\\results\\M1_S1_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN EXPERIMENTS (This uses the new src.experiments module)\n",
    "\n",
    "df_results = experiments.run_unsupervised_benchmark(scenarios)\n",
    "\n",
    "# Save results\n",
    "save_path = config.RESULTS_DIR / 'M1_S1_results.csv'\n",
    "df_results.to_csv(save_path, index=False)\n",
    "print(f\"üíæ Results saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51bf6fe",
   "metadata": {},
   "source": [
    "## 4. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e84b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show interactive table\n",
    "show(df_results.sort_values('auprc', ascending=False), classes=\"display compact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot of AUPRC Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_results, x='model', y='auprc', hue='filter', palette='viridis')\n",
    "plt.title('M1/S1 Performance (AUPRC) by Model and Filter')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(title='POS Filter', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa5422",
   "metadata": {},
   "source": [
    "## 5. Deep Dive: Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97953bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get Winner\n",
    "best_run = df_results.sort_values('auprc', ascending=False).iloc[0]\n",
    "print(f\"üèÜ WINNER: {best_run['model']} ({best_run['filter']})\")\n",
    "print(f\"   AUPRC: {best_run['auprc']:.4f}\")\n",
    "print(f\"   F1:    {best_run['f1']:.4f}\")\n",
    "\n",
    "# 2. Reload Data for Winner\n",
    "data_best = data_splitting.get_train_val_test_splits(\n",
    "    scenario='baseline', \n",
    "    level='token', \n",
    "    filter_type=best_run['filter']\n",
    ")\n",
    "\n",
    "# 3. Retrain (to get the object)\n",
    "model = models.get_unsupervised_model(best_run['model'])\n",
    "model.fit(data_best['X_train'][data_best['y_train'] == 0])\n",
    "\n",
    "# 4. Get Scores\n",
    "scores_val = model.decision_function(data_best['X_val'])\n",
    "scores_test = model.decision_function(data_best['X_test'])\n",
    "\n",
    "# 5. Optimal Threshold (from Val)\n",
    "threshold, _ = evaluation.find_optimal_threshold(data_best['y_val'], scores_val, metric='f1')\n",
    "print(f\"‚öôÔ∏è Optimal Threshold (from Val): {threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9578a",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88705335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Anomaly Score Histogram\n",
    "visualization.plot_anomaly_histogram(\n",
    "    scores_test, \n",
    "    data_best['y_test'], \n",
    "    threshold=threshold,\n",
    "    title=f\"Anomaly Scores: {best_run['model']} ({best_run['filter']})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Precision-Recall Curve\n",
    "visualization.plot_pr_curve(\n",
    "    data_best['y_test'], \n",
    "    scores_test, \n",
    "    title=f\"PR Curve: {best_run['model']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c195205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Confusion Matrix\n",
    "y_pred_test = (scores_test > threshold).astype(int)\n",
    "visualization.plot_confusion_matrix_heatmap(\n",
    "    data_best['y_test'], \n",
    "    y_pred_test, \n",
    "    normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158d7cf",
   "metadata": {},
   "source": [
    "## 6. Qualitative Analysis (Export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "df_qual = pd.DataFrame({\n",
    "    'token_text': data_best['meta_test']['analyzed_token'],\n",
    "    'full_text': data_best['meta_test']['text'],\n",
    "    'true_label': data_best['y_test'],\n",
    "    'pred_label': y_pred_test,\n",
    "    'anomaly_score': scores_test,\n",
    "    'document_id': data_best['meta_test']['document_id']\n",
    "})\n",
    "\n",
    "# Add Error Category\n",
    "conditions = [\n",
    "    (df_qual.true_label == 1) & (df_qual.pred_label == 1),\n",
    "    (df_qual.true_label == 0) & (df_qual.pred_label == 0),\n",
    "    (df_qual.true_label == 0) & (df_qual.pred_label == 1),\n",
    "    (df_qual.true_label == 1) & (df_qual.pred_label == 0)\n",
    "]\n",
    "df_qual['category'] = np.select(conditions, ['TP', 'TN', 'FP', 'FN'])\n",
    "\n",
    "# Save\n",
    "qual_path = config.RESULTS_DIR / f\"M1_S1_qualitative_{best_run['model']}.csv\"\n",
    "df_qual.to_csv(qual_path, index=False)\n",
    "print(f\"üìù Qualitative analysis saved to: {qual_path}\")\n",
    "\n",
    "# Show top False Positives (High score, but neutral)\n",
    "print(\"\\n‚ùå Top False Positives (Model thought it was anomaly, but it's not):\")\n",
    "show(df_qual[df_qual.category == 'FP'].sort_values('anomaly_score', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
