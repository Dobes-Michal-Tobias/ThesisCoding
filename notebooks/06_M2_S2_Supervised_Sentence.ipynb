{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 06: M2/S2 - Supervised Classification (Sentence Level)\n",
    "\n",
    "**C√≠l:** Natr√©novat klasifik√°tory na √∫rovni cel√Ωch vƒõt.\n",
    "**Hypot√©za:** Vƒõta nese v√≠ce kontextu ne≈æ samotn√© slovo. Funguje l√©pe pr≈Ømƒõr v≈°ech token≈Ø (**Mean Pooling**) nebo speci√°ln√≠ token (**[CLS]**)?\n",
    "\n",
    "**Sc√©n√°≈ôe:**\n",
    "* **S2a - Gold Balanced:** Tr√©nink na Gold datech (undersampling L0 na 1:1).\n",
    "* **S2b - Hybrid:** Tr√©nink na mixu Gold (L0) + Silver (L1).\n",
    "\n",
    "**Pooling Metody:**\n",
    "* **Mean:** Pr≈Ømƒõr embedding≈Ø v≈°ech slov ve vƒõtƒõ.\n",
    "* **CLS:** Embedding speci√°ln√≠ho tokenu [CLS] (reprezentace cel√© sekvence dle BERTa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "from itables import show\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Auto-reload modules for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Add src to path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "\n",
    "# Vlastn√≠ moduly\n",
    "import config\n",
    "import data_splitting\n",
    "import models\n",
    "import evaluation\n",
    "import visualization\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Nastaven√≠ vizualizace\n",
    "visualization.setup_style()\n",
    "\n",
    "print(f\"‚úÖ Setup complete. Results dir: {config.RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "datacheck",
   "metadata": {},
   "source": [
    "## 2. Data Check\n",
    "Ovƒõ≈ô√≠me poƒçty vƒõt pro jednotliv√© sc√©n√°≈ôe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS_TO_CHECK = ['baseline', 'hybrid']\n",
    "POOLING = 'mean' # Poƒçty jsou stejn√© pro mean i cls, li≈°√≠ se jen dimenze X\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"üìä DATA CHECK REPORT (M2/S2 - Sentence Level)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for scenario in SCENARIOS_TO_CHECK:\n",
    "    print(f\"\\nüîπ SC√âN√Å≈ò: {scenario.upper()}\")\n",
    "    try:\n",
    "        data = data_splitting.get_train_val_test_splits(\n",
    "            scenario=scenario,\n",
    "            level='sentence',\n",
    "            pooling=POOLING,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        def print_stats(name, y):\n",
    "            n_l0, n_l1 = np.sum(y == 0), np.sum(y == 1)\n",
    "            ratio = n_l0 / n_l1 if n_l1 > 0 else 0\n",
    "            print(f\"   {name:<6} | Total: {len(y):<5} | L0: {n_l0:<4} | L1: {n_l1:<4} | Ratio: {ratio:.1f}:1\")\n",
    "\n",
    "        print_stats(\"TRAIN\", data['y_train'])\n",
    "        print_stats(\"VAL\",   data['y_val'])\n",
    "        print_stats(\"TEST\",  data['y_test'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Chyba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experiments",
   "metadata": {},
   "source": [
    "## 3. Experiment Loop (Pooling & Scenarios)\n",
    "Tr√©nujeme kombinace: **Sc√©n√°≈ô x Pooling x Model**.\n",
    "\n",
    "**Sc√©n√°≈ôe:**\n",
    "* **S2a:** Baseline (Gold) + Manual Undersampling\n",
    "* **S2b:** Hybrid (Gold L0 + Silver L1)\n",
    "\n",
    "**Pooling:** `mean` vs `cls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cesta pro v√Ωsledky\n",
    "RESULTS_PATH = config.RESULTS_DIR / \"M2_S2_experiment_results_v1.csv\"\n",
    "\n",
    "# Definice experiment≈Ø (Sc√©n√°≈ôe)\n",
    "SCENARIOS = [\n",
    "    {'id': 'S2a', 'name': 'Gold Balanced', 'scenario': 'baseline', 'balance_train': True},\n",
    "    {'id': 'S2b', 'name': 'Hybrid (G+S)',  'scenario': 'hybrid',   'balance_train': False}, # Hybrid je u≈æ balanced z modulu\n",
    "]\n",
    "\n",
    "POOLING_METHODS = ['mean', 'cls']\n",
    "\n",
    "# MODELS_TO_TEST = ['LogReg', 'SVM (RBF)'] # Pro rychlost. SVM (Lin) m≈Ø≈æe≈° p≈ôidat.          # Pro kr√°tk√Ω test\n",
    "MODELS_TO_TEST = [\"LogReg\", \"SVM (RBF)\", \"XGBoost\", \"Dummy\", \"SVM (Lin)\", \"NaiveBayes\", \"RandForest\"]\n",
    "\n",
    "if models.XGBOOST_AVAILABLE:\n",
    "    MODELS_TO_TEST.append('XGBoost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_f1 = 0.0\n",
    "best_run = None\n",
    "\n",
    "print(f\"üöÄ STARTING SENTENCE LEVEL EXPERIMENTS (All Metrics: P/R/F1/AUC)...\")\n",
    "print(f\"üíæ Results path: {RESULTS_PATH}\")\n",
    "\n",
    "for pooling in POOLING_METHODS:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"üåä POOLING METHOD: {pooling.upper()}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    \n",
    "    for exp in SCENARIOS:\n",
    "        print(f\"\\n   üß™ SCENARIO: {exp['id']} - {exp['name']}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Naƒçten√≠ dat\n",
    "            data = data_splitting.get_train_val_test_splits(\n",
    "                scenario=exp['scenario'],\n",
    "                level='sentence',\n",
    "                pooling=pooling,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            X_train, y_train = data['X_train'], data['y_train']\n",
    "            X_val, y_val     = data['X_val'], data['y_val']\n",
    "            X_test, y_test   = data['X_test'], data['y_test']\n",
    "            \n",
    "            print(f\"      üìä Train Size: {X_train.shape[0]} (L0: {sum(y_train==0)}, L1: {sum(y_train==1)})\")\n",
    "\n",
    "            # 2. Tr√©nink Model≈Ø\n",
    "            for model_name in MODELS_TO_TEST:\n",
    "                print(f\"      ‚öôÔ∏è {model_name}...\")\n",
    "                \n",
    "                try:\n",
    "                    clf = models.get_supervised_model(model_name, random_state=42)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Z√≠sk√°n√≠ sk√≥re\n",
    "                    if hasattr(clf, \"predict_proba\"):\n",
    "                        s_train = clf.predict_proba(X_train)[:, 1]\n",
    "                        s_val   = clf.predict_proba(X_val)[:, 1]\n",
    "                        s_test  = clf.predict_proba(X_test)[:, 1]\n",
    "                    else:\n",
    "                        s_train = clf.decision_function(X_train)\n",
    "                        s_val   = clf.decision_function(X_val)\n",
    "                        s_test  = clf.decision_function(X_test)\n",
    "                    \n",
    "                    # Threshold z Val\n",
    "                    threshold, _ = evaluation.find_optimal_threshold(y_val, s_val, metric='f1')\n",
    "                    \n",
    "                    # V√Ωpoƒçet metrik pro V≈†ECHNY sady\n",
    "                    m_train = evaluation.calculate_metrics(y_train, (s_train > threshold).astype(int), s_train)\n",
    "                    m_val   = evaluation.calculate_metrics(y_val, (s_val > threshold).astype(int), s_val)\n",
    "                    m_test  = evaluation.calculate_metrics(y_test, (s_test > threshold).astype(int), s_test)\n",
    "                    \n",
    "                    # Log (Ukl√°d√°me komplet v≈°echno)\n",
    "                    res = {\n",
    "                        'id': exp['id'],\n",
    "                        'scenario': exp['scenario'],\n",
    "                        'scenario_name': exp['name'],\n",
    "                        'pooling': pooling,\n",
    "                        'model': model_name,\n",
    "                        'threshold': threshold,\n",
    "                        \n",
    "                        # Train Metrics\n",
    "                        'train_f1': m_train['f1'], 'train_auprc': m_train['avg_precision'], 'train_roc_auc': m_train['roc_auc'],\n",
    "                        'train_prec': m_train['precision'], 'train_rec': m_train['recall'], # <--- NOV√â\n",
    "                        \n",
    "                        # Val Metrics\n",
    "                        'val_f1': m_val['f1'],     'val_auprc': m_val['avg_precision'],     'val_roc_auc': m_val['roc_auc'],\n",
    "                        'val_prec': m_val['precision'], 'val_rec': m_val['recall'],         # <--- NOV√â\n",
    "                        \n",
    "                        # Test Metrics\n",
    "                        'test_f1': m_test['f1'],   'test_auprc': m_test['avg_precision'],   'test_roc_auc': m_test['roc_auc'],\n",
    "                        'test_prec': m_test['precision'], 'test_rec': m_test['recall']      # <--- NOV√â\n",
    "                    }\n",
    "                    results.append(res)\n",
    "                    pd.DataFrame(results).to_csv(RESULTS_PATH, index=False)\n",
    "                    \n",
    "                    # Best Run Check (St√°le podle F1 na testu)\n",
    "                    if m_test['f1'] > best_f1:\n",
    "                        best_f1 = m_test['f1']\n",
    "                        best_run = {\n",
    "                            'info': res,\n",
    "                            'model': clf,\n",
    "                            'data': data,\n",
    "                            'scores_test': s_test,\n",
    "                            'y_test': y_test\n",
    "                        }\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"      ‚ùå Error {model_name}: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error loading data: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All experiments finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results",
   "metadata": {},
   "source": [
    "## 4. Results Overview\n",
    "Srovn√°n√≠ vlivu Poolingu a Sc√©n√°≈ô≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. RESULTS OVERVIEW\n",
    "# =============================================================================\n",
    "\n",
    "# Naƒçten√≠ v√Ωsledk≈Ø\n",
    "if RESULTS_PATH.exists():\n",
    "    df_results = pd.read_csv(RESULTS_PATH)\n",
    "else:\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# A) PIVOT TABLE (Tabulka v√Ωsledk≈Ø)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"üìä SROVN√ÅN√ç AUPRC (Pooling x Scenario):\")\n",
    "\n",
    "pivot = df_results.pivot_table(\n",
    "    values='test_auprc', \n",
    "    index='model',        \n",
    "    columns=['pooling', 'scenario_name'], # Vytvo≈ô√≠ MultiIndex ve sloupc√≠ch\n",
    "    aggfunc='max'\n",
    ")\n",
    "\n",
    "# ‚úÖ OPRAVA SORTINGU PRO MULTIINDEX\n",
    "# Vypoƒç√≠t√°me pr≈Ømƒõr pro ka≈æd√Ω ≈ô√°dek (model) bokem\n",
    "mean_scores = pivot.mean(axis=1)\n",
    "# Z√≠sk√°me se≈ôazen√Ω seznam model≈Ø\n",
    "sorted_models = mean_scores.sort_values(ascending=False).index\n",
    "# P≈ôe≈ôad√≠me tabulku podle tohoto seznamu\n",
    "pivot = pivot.reindex(sorted_models)\n",
    "\n",
    "# Zobraz√≠me (bez sloupce mean, ten byl jen pro ≈ôazen√≠)\n",
    "display(pivot.style.background_gradient(cmap='Blues', axis=None).format(\"{:.4f}\"))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# B) VIZUALIZACE (Pooling Breakdown)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nüìä DETAILN√ç GRAFY: MEAN vs CLS (Train vs Test)\")\n",
    "\n",
    "# P≈ô√≠prava dat (kopie)\n",
    "df_viz = df_results.copy()\n",
    "\n",
    "# Seznam metrik, kter√© chceme vykreslit\n",
    "metrics_to_plot = ['auprc', 'f1',] \n",
    "\n",
    "for m in metrics_to_plot:\n",
    "    # Kontrola, zda m√°me data (nap≈ô. 'test_prec')\n",
    "    if f'test_{m}' in df_viz.columns:\n",
    "        print(f\"   Generating plot for: {m.upper()}...\")\n",
    "        \n",
    "        visualization.plot_pooling_breakdown(\n",
    "            df_viz, \n",
    "            metric=m,\n",
    "            save_path=config.RESULTS_DIR / f\"M2_S2_Pooling_Breakdown_{m.upper()}.png\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Metrika '{m}' v datech chyb√≠.\")\n",
    "\n",
    "print(\"\\n‚úÖ Vizualizace hotova.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deep_dive",
   "metadata": {},
   "source": [
    "## 5. Deep Dive: Winner Analysis\n",
    "Detailn√≠ pohled na nejlep≈°√≠ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "winner_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DEEP DIVE: WINNER ANALYSIS (Retrain & Metrics)\n",
    "\n",
    "if RESULTS_PATH.exists():\n",
    "    df_results = pd.read_csv(RESULTS_PATH)\n",
    "    best_row = df_results.sort_values('test_f1', ascending=False).iloc[0]\n",
    "    \n",
    "    print(f\"üèÜ WINNER: {best_row['model']} ({best_row['scenario_name']})\")\n",
    "    print(f\"üåä Pooling: {best_row['pooling'].upper()}\")\n",
    "    print(f\"üìä F1 (Test): {best_row['test_f1']:.4f}\")\n",
    "    print(f\"üéØ Threshold: {best_row['threshold']:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 1. Reload Data\n",
    "    print(f\"üîÑ Reloading data...\")\n",
    "    data_best = data_splitting.get_train_val_test_splits(\n",
    "        scenario=best_row['scenario'],\n",
    "        level='sentence',\n",
    "        pooling=best_row['pooling'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train_b, y_train_b = data_best['X_train'], data_best['y_train']\n",
    "    X_val_b,   y_val_b   = data_best['X_val'],   data_best['y_val']\n",
    "    X_test_b,  y_test_b  = data_best['X_test'],  data_best['y_test']\n",
    "    \n",
    "    # 2. Retrain Model (na pln√Ωch datech, bez manual undersamplingu)\n",
    "    print(f\"‚öôÔ∏è Retraining {best_row['model']} on full train set ({len(X_train_b)} samples)...\")\n",
    "    clf = models.get_supervised_model(best_row['model'], random_state=42)\n",
    "    clf.fit(X_train_b, y_train_b)\n",
    "    \n",
    "    # 3. Z√≠sk√°n√≠ sk√≥re pro v≈°echny sady\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        s_train = clf.predict_proba(X_train_b)[:, 1]\n",
    "        s_val   = clf.predict_proba(X_val_b)[:, 1]\n",
    "        s_test  = clf.predict_proba(X_test_b)[:, 1]\n",
    "    else:\n",
    "        s_train = clf.decision_function(X_train_b)\n",
    "        s_val   = clf.decision_function(X_val_b)\n",
    "        s_test  = clf.decision_function(X_test_b)\n",
    "        \n",
    "    # 4. Aplikace prahu (pou≈æ√≠v√°me ten ulo≈æen√Ω z CSV)\n",
    "    thresh = best_row['threshold']\n",
    "    p_train = (s_train > thresh).astype(int)\n",
    "    p_val   = (s_val > thresh).astype(int)\n",
    "    p_test  = (s_test > thresh).astype(int)\n",
    "    \n",
    "    # 5. Detailn√≠ Report Metrik\n",
    "    print(f\"\\nüì¢ DETAILED PERFORMANCE REPORT (Threshold: {thresh:.4f})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    def print_metrics(name, y_true, y_pred, scores):\n",
    "        m = evaluation.calculate_metrics(y_true, y_pred, scores)\n",
    "        print(f\"\\nüîπ {name} SET Results ({len(y_true)} samples):\")\n",
    "        print(f\"   F1 Score:  {m['f1']:.4f}\")\n",
    "        print(f\"   AUPRC:     {m['avg_precision']:.4f}\")\n",
    "        print(f\"   ROC AUC:   {m['roc_auc']:.4f}\")\n",
    "        print(f\"   Precision: {m['precision']:.4f}\")\n",
    "        print(f\"   Recall:    {m['recall']:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(classification_report(y_true, y_pred, target_names=['Neutral (L0)', 'Bias (L1)'], digits=4))\n",
    "\n",
    "    print_metrics(\"TRAIN\", y_train_b, p_train, s_train)\n",
    "    print_metrics(\"VAL\",   y_val_b,   p_val,   s_val)\n",
    "    print_metrics(\"TEST\",  y_test_b,  p_test,  s_test)\n",
    "    \n",
    "    # 6. Ulo≈æen√≠ do promƒõnn√© pro dal≈°√≠ bu≈àky (Vizualizace)\n",
    "    best_run = {\n",
    "        'info': best_row.to_dict(),\n",
    "        'model': clf,\n",
    "        'data': data_best,\n",
    "        'scores_test': s_test,\n",
    "        'y_test': y_test_b,\n",
    "        'y_pred_test': p_test, # P≈ôidal jsem i bin√°rn√≠ predikce\n",
    "        'threshold': thresh\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nem√°m v√Ωsledky. Spus≈• nejprve tr√©novac√≠ smyƒçku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Vizualizace\n",
    "visualization.plot_confusion_matrix_heatmap(y_test_b, y_pred, normalize=True, title=\"CM (Normalized)\")\n",
    "visualization.plot_pr_curve(y_test_b, scores_test, title=\"PR Curve\")\n",
    "visualization.plot_model_calibration(y_test_b, scores_test, title=\"Calibration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "projections",
   "metadata": {},
   "source": [
    "#### 6. Projekce Embedding≈Ø\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_projections",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Poƒç√≠t√°m projekce vƒõt...\")\n",
    "projs, idxs = visualization.compute_projections(X_test_b, methods=['PCA', 't-SNE'], random_state=42)\n",
    "y_viz = y_test_b[idxs]\n",
    "y_pred_viz = y_pred[idxs]\n",
    "\n",
    "for m, coords in projs.items():\n",
    "    # GT\n",
    "    visualization.plot_embedding_projection(\n",
    "        coords, pd.Series(y_viz).map({0:'Neutral', 1:'Bias'}), \n",
    "        palette={'Neutral': config.COLORS['l0'], 'Bias': config.COLORS['l1']},\n",
    "        title=f\"{m} - Ground Truth\"\n",
    "    )\n",
    "    # Errors\n",
    "    visualization.plot_error_analysis_projection(\n",
    "        coords, y_viz, y_pred_viz, method_name=m\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4a1e5",
   "metadata": {},
   "source": [
    "## 6. Qualitative Analysis (Error Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22615217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. QUALITATIVE ANALYSIS (Detailn√≠ pohled na chyby)\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Vezmeme existuj√≠c√≠ metadata (obsahuj√≠ document_id, sentence_id, text...)\n",
    "# Pou≈æijeme .copy(), abychom neovlivnili p≈Øvodn√≠ data\n",
    "df_qual = data_best['meta_test'].copy()\n",
    "\n",
    "# 2. P≈ôid√°me predikce modelu\n",
    "df_qual['true_label'] = y_test_b\n",
    "df_qual['pred_label'] = y_pred\n",
    "df_qual['anomaly_score'] = scores_test\n",
    "\n",
    "# 3. Urƒçen√≠ kategorie (TP, TN, FP, FN)\n",
    "conds = [\n",
    "    (df_qual['true_label'] == 1) & (df_qual['pred_label'] == 1), # TP\n",
    "    (df_qual['true_label'] == 0) & (df_qual['pred_label'] == 0), # TN\n",
    "    (df_qual['true_label'] == 0) & (df_qual['pred_label'] == 1), # FP\n",
    "    (df_qual['true_label'] == 1) & (df_qual['pred_label'] == 0)  # FN\n",
    "]\n",
    "\n",
    "df_qual['category'] = np.select(conds, ['TP', 'TN', 'FP', 'FN'], default='UNKNOWN')\n",
    "\n",
    "# 4. √öklid sloupc≈Ø (se≈ôad√≠me je logicky)\n",
    "# Definujeme preferovan√© po≈ôad√≠\n",
    "preferred_cols = ['document_id', 'sentence_id', 'text', 'true_label', 'pred_label', 'anomaly_score', 'category']\n",
    "\n",
    "# Vybereme jen ty, kter√© v datech skuteƒçnƒõ m√°me (aby to nepadalo, kdyby 'sentence_id' chybƒõlo)\n",
    "final_cols = [c for c in preferred_cols if c in df_qual.columns]\n",
    "\n",
    "# Pokud zbyly nƒõjak√© dal≈°√≠ sloupce v metadatech, p≈ôid√°me je nakonec\n",
    "remaining_cols = [c for c in df_qual.columns if c not in final_cols]\n",
    "df_qual = df_qual[final_cols + remaining_cols]\n",
    "\n",
    "# 5. V√Ωpis v√Ωsledk≈Ø\n",
    "print(\"\\n‚ùå TOP 5 FP (Model vid√≠ bias, kde nen√≠ - False Alarm):\")\n",
    "display(df_qual[df_qual['category'] == 'FP'].sort_values('anomaly_score', ascending=False).head(5))\n",
    "\n",
    "print(\"\\n‚ùå TOP 5 FN (Model p≈ôehl√©dl bias - Missed Detection):\")\n",
    "display(df_qual[df_qual['category'] == 'FN'].sort_values('anomaly_score', ascending=True).head(5))\n",
    "\n",
    "# 6. Ulo≈æen√≠\n",
    "save_path = config.RESULTS_DIR / \"M2_S2_Qualitative_Analysis.csv\"\n",
    "df_qual.to_csv(save_path, index=False)\n",
    "print(f\"\\nüíæ Detailn√≠ anal√Ωza ulo≈æena: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
