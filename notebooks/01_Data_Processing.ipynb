{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 01: Data Processing Pipeline\n",
    "\n",
    "**Purpose:** Process raw JSONL data into clean DataFrames with embeddings.\n",
    "\n",
    "**Run this notebook ONCE** to create processed data files. After that, use `02_EDA.ipynb` for analysis and experiment notebooks for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. **Loads raw JSONL** files (GOLD and SILVER)\n",
    "2. **Adds document IDs** automatically (one per line)\n",
    "3. **Processes with NLP pipeline:**\n",
    "   - spaCy-UDPipe for POS tagging\n",
    "   - RobeCzech BERT for embeddings\n",
    "4. **Computes embeddings INDEPENDENTLY** per sentence (prevents data leakage)\n",
    "5. **Saves to DataFrame pickles** with full metadata\n",
    "6. **Creates integrity checksums** (SHA256)\n",
    "\n",
    "## Output Files\n",
    "\n",
    "After running this notebook, you'll have:\n",
    "```\n",
    "data/processed/\n",
    "‚îú‚îÄ‚îÄ gold_tokens.pkl          # Token-level data\n",
    "‚îú‚îÄ‚îÄ gold_tokens.pkl.sha256   # Integrity check\n",
    "‚îú‚îÄ‚îÄ gold_sentences.pkl       # Sentence-level data\n",
    "‚îú‚îÄ‚îÄ gold_sentences.pkl.sha256\n",
    "‚îú‚îÄ‚îÄ silver_tokens.pkl\n",
    "‚îú‚îÄ‚îÄ silver_tokens.pkl.sha256\n",
    "‚îú‚îÄ‚îÄ silver_sentences.pkl\n",
    "‚îî‚îÄ‚îÄ silver_sentences.pkl.sha256\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **WARNING:** Processing takes time (~5-10 minutes for GOLD, ~30-60 minutes for SILVER)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration loaded. Device: cpu\n",
      "‚úÖ Setup complete\n",
      "   Device: cpu\n",
      "   Model: ufal/robeczech-base\n",
      "   Output: C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Jupyter magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add src to path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "# Import modules\n",
    "import config\n",
    "from load_preprocess_data import run_full_pipeline\n",
    "\n",
    "print(\"‚úÖ Setup complete\")\n",
    "print(f\"   Device: {config.DEVICE}\")\n",
    "print(f\"   Model: {config.MODEL_NAME}\")\n",
    "print(f\"   Output: {config.PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_header",
   "metadata": {},
   "source": [
    "## 2. Validate Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Checking raw data files...\n",
      "\n",
      "‚úÖ Gold raw data found: C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\raw\\GOLD_data_raw.jsonl\n",
      "   ‚Üí 521 entries detected\n",
      "\n",
      "‚úÖ Silver raw data found: C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\raw\\SILVER_data_raw.jsonl\n",
      "   ‚Üí 1903 entries detected\n",
      "\n",
      "üîç Validating configuration...\n",
      "‚úÖ Configuration validated successfully\n"
     ]
    }
   ],
   "source": [
    "# Check if raw data files exist\n",
    "print(\"üìã Checking raw data files...\\n\")\n",
    "\n",
    "if config.PATH_GOLD_RAW.exists():\n",
    "    print(f\"‚úÖ Gold raw data found: {config.PATH_GOLD_RAW}\")\n",
    "    \n",
    "    # Count lines\n",
    "    with open(config.PATH_GOLD_RAW, 'r', encoding='utf-8') as f:\n",
    "        gold_lines = sum(1 for _ in f)\n",
    "    print(f\"   ‚Üí {gold_lines} entries detected\")\n",
    "else:\n",
    "    print(f\"‚ùå Gold raw data NOT found: {config.PATH_GOLD_RAW}\")\n",
    "    print(\"   Please add GOLD_data_raw.jsonl to data/raw/\")\n",
    "\n",
    "if config.PATH_SILVER_RAW.exists():\n",
    "    print(f\"\\n‚úÖ Silver raw data found: {config.PATH_SILVER_RAW}\")\n",
    "    \n",
    "    # Count lines\n",
    "    with open(config.PATH_SILVER_RAW, 'r', encoding='utf-8') as f:\n",
    "        silver_lines = sum(1 for _ in f)\n",
    "    print(f\"   ‚Üí {silver_lines} entries detected\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Silver raw data NOT found: {config.PATH_SILVER_RAW}\")\n",
    "    print(\"   (Silver is optional - you can skip it)\")\n",
    "\n",
    "# Validate configuration\n",
    "print(\"\\nüîç Validating configuration...\")\n",
    "try:\n",
    "    config.validate_config()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Validation warning: {e}\")\n",
    "    print(\"   Continuing anyway...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview_header",
   "metadata": {},
   "source": [
    "## 3. Preview Raw Data\n",
    "\n",
    "Let's check what the raw data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preview_raw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ GOLD Raw Data Preview (first 3 entries):\n",
      "\n",
      "Entry 1:\n",
      "  context_prev: Z√°soby zemn√≠ho plynu v evropsk√Ωch skladech dos√°hly rekordn√≠ ...\n",
      "  target_sentence: Souƒçasn√° √∫rove≈à spot≈ôeby energie je alarmuj√≠c√≠....\n",
      "  label: 1\n",
      "  source: LLM\n",
      "  target_token: alarmuj√≠c√≠\n",
      "  ‚ÑπÔ∏è  No document_id (will be auto-generated)\n",
      "\n",
      "Entry 2:\n",
      "  context_prev: Pr≈Ømƒõrn√° mzda v ƒåesk√© republice ve t≈ôet√≠m ƒçtvrtlet√≠ meziroƒçn...\n",
      "  target_sentence: Rozd√≠l mezi platy mu≈æ≈Ø a ≈æen z≈Øst√°v√° i na d√°le neuvƒõ≈ôiteln√Ω....\n",
      "  label: 1\n",
      "  source: Author\n",
      "  target_token: neuvƒõ≈ôiteln√Ω\n",
      "  ‚ÑπÔ∏è  No document_id (will be auto-generated)\n",
      "\n",
      "Entry 3:\n",
      "  context_prev: V posledn√≠ch mƒõs√≠c√≠ch do≈°lo k v√Ωrazn√©mu poklesu stavebn√≠ pro...\n",
      "  target_sentence: Tempo v√Ωstavby nov√Ωch byt≈Ø je ≈æalostn√©....\n",
      "  label: 1\n",
      "  source: LLM\n",
      "  target_token: ≈æalostn√©\n",
      "  ‚ÑπÔ∏è  No document_id (will be auto-generated)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"üìÑ GOLD Raw Data Preview (first 3 entries):\\n\")\n",
    "\n",
    "if config.PATH_GOLD_RAW.exists():\n",
    "    with open(config.PATH_GOLD_RAW, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            entry = json.loads(line)\n",
    "            print(f\"Entry {i+1}:\")\n",
    "            print(f\"  context_prev: {entry.get('context_prev', 'N/A')[:60]}...\")\n",
    "            print(f\"  target_sentence: {entry.get('target_sentence', 'N/A')[:60]}...\")\n",
    "            print(f\"  label: {entry.get('label')}\")\n",
    "            print(f\"  source: {entry.get('source')}\")\n",
    "            print(f\"  target_token: {entry.get('target_token')}\")\n",
    "            \n",
    "            # Check if document_id exists\n",
    "            if 'document_id' in entry:\n",
    "                print(f\"  ‚úÖ Has document_id: {entry['document_id']}\")\n",
    "            else:\n",
    "                print(f\"  ‚ÑπÔ∏è  No document_id (will be auto-generated)\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GOLD file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gold_header",
   "metadata": {},
   "source": [
    "## 4. Process GOLD Dataset\n",
    "\n",
    "**GOLD Dataset:** High-quality, manually annotated data (~520 documents).\n",
    "\n",
    "This will:\n",
    "1. Load GOLD_data_raw.jsonl\n",
    "2. **Auto-generate document IDs** (gold_doc_0001, gold_doc_0002, ...)\n",
    "3. Process each sentence INDEPENDENTLY (no cross-sentence context)\n",
    "4. Extract token-level and sentence-level embeddings\n",
    "5. Save to pickles with metadata\n",
    "\n",
    "### Expected Progress:\n",
    "- Loading models: ~30 seconds\n",
    "- Processing sentences: ~5-10 minutes (with progress bar)\n",
    "- Saving files: ~10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "process_gold",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:27:40,060 - INFO - üöÄ Starting full pipeline for GOLD dataset\n",
      "2026-02-22 19:27:40,061 - INFO - Loading spaCy-UDPipe model ('cs-pdt')...\n",
      "2026-02-22 19:27:40,062 - INFO - Downloading spaCy-UDPipe model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Processing GOLD dataset...\n",
      "\n",
      "This may take 5-10 minutes depending on your hardware.\n",
      "Progress bars will show detailed status.\n",
      "\n",
      "============================================================\n",
      "Downloaded pre-trained UDPipe model for 'cs-pdt' language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:27:53,315 - INFO - Loading RobeCzech model ('ufal/robeczech-base')...\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2026-02-22 19:27:54,673 - INFO - ‚úÖ Models loaded successfully\n",
      "2026-02-22 19:27:54,677 - WARNING - Skipping invalid JSON on line 521: Expecting value: line 2 column 1 (char 1)\n",
      "2026-02-22 19:27:54,678 - INFO - Loaded 520 entries from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\raw\\GOLD_data_raw.jsonl\n",
      "Processing gold data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 520/520 [00:49<00:00, 10.51it/s]\n",
      "2026-02-22 19:28:44,194 - INFO - ‚úÖ Processed gold:\n",
      "2026-02-22 19:28:44,195 - INFO -    - Token-level: 17557 rows\n",
      "2026-02-22 19:28:44,196 - INFO -    - Sentence-level: 1560 rows\n",
      "2026-02-22 19:28:46,975 - INFO - üíæ Saved processed data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "‚úÖ GOLD dataset processing complete!\n",
      "   Tokens: 17,557 rows\n",
      "   Sentences: 1,560 rows\n",
      "   Documents: 520 unique\n",
      "   LJMPNIK words: 305\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Processing GOLD dataset...\\n\")\n",
    "print(\"This may take 5-10 minutes depending on your hardware.\")\n",
    "print(\"Progress bars will show detailed status.\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "token_df_gold, sentence_df_gold = run_full_pipeline('gold')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ GOLD dataset processing complete!\")\n",
    "print(f\"   Tokens: {len(token_df_gold):,} rows\")\n",
    "print(f\"   Sentences: {len(sentence_df_gold):,} rows\")\n",
    "print(f\"   Documents: {token_df_gold['document_id'].nunique():,} unique\")\n",
    "print(f\"   LJMPNIK words: {(token_df_gold['is_target'] == True).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gold_preview_header",
   "metadata": {},
   "source": [
    "### 4.1 Preview Processed GOLD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preview_gold_tokens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä GOLD Token-Level Data Preview:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>position</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>embedding</th>\n",
       "      <th>is_target</th>\n",
       "      <th>label</th>\n",
       "      <th>token_label</th>\n",
       "      <th>is_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Souƒçasn√°</td>\n",
       "      <td>souƒçasn√Ω</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[0.05658283, -0.16128066, -0.083715945, 0.0036...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_1</td>\n",
       "      <td>1</td>\n",
       "      <td>√∫rove≈à</td>\n",
       "      <td>√∫rove≈à</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.32223943, -0.046616577, 0.17479904, -0.0836...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_2</td>\n",
       "      <td>2</td>\n",
       "      <td>spot≈ôeby</td>\n",
       "      <td>spot≈ôeba</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.2664389, -0.040305506, 0.043529328, -0.0057...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_3</td>\n",
       "      <td>3</td>\n",
       "      <td>energie</td>\n",
       "      <td>energie</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[-0.14703438, 0.017672857, 0.04595686, 0.16327...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_4</td>\n",
       "      <td>4</td>\n",
       "      <td>je</td>\n",
       "      <td>b√Ωt</td>\n",
       "      <td>AUX</td>\n",
       "      <td>[-0.49623346, -0.17490284, -0.014973694, 0.339...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_5</td>\n",
       "      <td>5</td>\n",
       "      <td>alarmuj√≠c√≠</td>\n",
       "      <td>alarmuj√≠c√≠</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[-0.085729636, -0.032963824, -0.12887268, 0.10...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>gold_doc_0001_target_tok_6</td>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[0.25777772, -0.08328905, 0.115178466, 0.11127...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_ctx_prev</td>\n",
       "      <td>gold_doc_0001_ctx_prev_tok_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z√°soby</td>\n",
       "      <td>z√°soba</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.19291194, 0.13453041, 0.05749755, -0.134289...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_ctx_prev</td>\n",
       "      <td>gold_doc_0001_ctx_prev_tok_1</td>\n",
       "      <td>1</td>\n",
       "      <td>zemn√≠ho</td>\n",
       "      <td>zemn√≠</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[0.09201947, 0.11344469, -0.0370981, 0.0397366...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_ctx_prev</td>\n",
       "      <td>gold_doc_0001_ctx_prev_tok_2</td>\n",
       "      <td>2</td>\n",
       "      <td>plynu</td>\n",
       "      <td>plyn</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[-0.017090743, -0.04328588, 0.08480315, 0.1402...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id             sentence_id                      token_id  \\\n",
       "0  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_0   \n",
       "1  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_1   \n",
       "2  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_2   \n",
       "3  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_3   \n",
       "4  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_4   \n",
       "5  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_5   \n",
       "6  gold_doc_0001    gold_doc_0001_target    gold_doc_0001_target_tok_6   \n",
       "7  gold_doc_0001  gold_doc_0001_ctx_prev  gold_doc_0001_ctx_prev_tok_0   \n",
       "8  gold_doc_0001  gold_doc_0001_ctx_prev  gold_doc_0001_ctx_prev_tok_1   \n",
       "9  gold_doc_0001  gold_doc_0001_ctx_prev  gold_doc_0001_ctx_prev_tok_2   \n",
       "\n",
       "   position        form       lemma    pos  \\\n",
       "0         0    Souƒçasn√°    souƒçasn√Ω    ADJ   \n",
       "1         1      √∫rove≈à      √∫rove≈à   NOUN   \n",
       "2         2    spot≈ôeby    spot≈ôeba   NOUN   \n",
       "3         3     energie     energie   NOUN   \n",
       "4         4          je         b√Ωt    AUX   \n",
       "5         5  alarmuj√≠c√≠  alarmuj√≠c√≠    ADJ   \n",
       "6         6           .           .  PUNCT   \n",
       "7         0      Z√°soby      z√°soba   NOUN   \n",
       "8         1     zemn√≠ho       zemn√≠    ADJ   \n",
       "9         2       plynu        plyn   NOUN   \n",
       "\n",
       "                                           embedding is_target  label  \\\n",
       "0  [0.05658283, -0.16128066, -0.083715945, 0.0036...     False      1   \n",
       "1  [0.32223943, -0.046616577, 0.17479904, -0.0836...     False      1   \n",
       "2  [0.2664389, -0.040305506, 0.043529328, -0.0057...     False      1   \n",
       "3  [-0.14703438, 0.017672857, 0.04595686, 0.16327...     False      1   \n",
       "4  [-0.49623346, -0.17490284, -0.014973694, 0.339...     False      1   \n",
       "5  [-0.085729636, -0.032963824, -0.12887268, 0.10...      True      1   \n",
       "6  [0.25777772, -0.08328905, 0.115178466, 0.11127...     False      1   \n",
       "7  [0.19291194, 0.13453041, 0.05749755, -0.134289...     False      0   \n",
       "8  [0.09201947, 0.11344469, -0.0370981, 0.0397366...     False      0   \n",
       "9  [-0.017090743, -0.04328588, 0.08480315, 0.1402...     False      0   \n",
       "\n",
       "   token_label  is_context  \n",
       "0            0       False  \n",
       "1            0       False  \n",
       "2            0       False  \n",
       "3            0       False  \n",
       "4            0       False  \n",
       "5            1       False  \n",
       "6            0       False  \n",
       "7            0        True  \n",
       "8            0        True  \n",
       "9            0        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Column Information:\n",
      "  - document_id: object\n",
      "  - sentence_id: object\n",
      "  - token_id: object\n",
      "  - position: int64\n",
      "  - form: object\n",
      "  - lemma: object\n",
      "  - pos: object\n",
      "  - embedding: array(768,)\n",
      "  - is_target: object\n",
      "  - label: int64\n",
      "  - token_label: int64\n",
      "  - is_context: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä GOLD Token-Level Data Preview:\\n\")\n",
    "display(token_df_gold.head(10))\n",
    "\n",
    "print(\"\\nüìã Column Information:\")\n",
    "for col in token_df_gold.columns:\n",
    "    dtype = token_df_gold[col].dtype\n",
    "    if col == 'embedding':\n",
    "        shape = token_df_gold[col].iloc[0].shape\n",
    "        print(f\"  - {col}: array{shape}\")\n",
    "    else:\n",
    "        print(f\"  - {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preview_gold_sentences",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä GOLD Sentence-Level Data Preview:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>is_context</th>\n",
       "      <th>context_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_target</td>\n",
       "      <td>Souƒçasn√° √∫rove≈à spot≈ôeby energie je alarmuj√≠c√≠ .</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_ctx_prev</td>\n",
       "      <td>Z√°soby zemn√≠ho plynu v evropsk√Ωch skladech dos...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>prev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gold_doc_0001</td>\n",
       "      <td>gold_doc_0001_ctx_next</td>\n",
       "      <td>Energetick√© spoleƒçnosti ozn√°mily stabiln√≠ dod√°...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold_doc_0002</td>\n",
       "      <td>gold_doc_0002_target</td>\n",
       "      <td>Rozd√≠l mezi platy mu≈æ≈Ø a ≈æen z≈Øst√°v√° i na d√°le...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gold_doc_0002</td>\n",
       "      <td>gold_doc_0002_ctx_prev</td>\n",
       "      <td>Pr≈Ømƒõrn√° mzda v ƒåesk√© republice ve t≈ôet√≠m ƒçtvr...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>prev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gold_doc_0002</td>\n",
       "      <td>gold_doc_0002_ctx_next</td>\n",
       "      <td>Statistici oƒçek√°vaj√≠ , ≈æe r≈Øst mezd zpomal√≠ v ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gold_doc_0003</td>\n",
       "      <td>gold_doc_0003_target</td>\n",
       "      <td>Tempo v√Ωstavby nov√Ωch byt≈Ø je ≈æalostn√© .</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gold_doc_0003</td>\n",
       "      <td>gold_doc_0003_ctx_prev</td>\n",
       "      <td>V posledn√≠ch mƒõs√≠c√≠ch do≈°lo k v√Ωrazn√©mu pokles...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>prev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gold_doc_0003</td>\n",
       "      <td>gold_doc_0003_ctx_next</td>\n",
       "      <td>Developersk√© spoleƒçnosti pl√°nuj√≠ nav√Ω≈°it inves...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gold_doc_0004</td>\n",
       "      <td>gold_doc_0004_target</td>\n",
       "      <td>Kvalita poskytovan√Ωch slu≈æeb je v≈°ak tristn√≠ .</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id             sentence_id  \\\n",
       "0  gold_doc_0001    gold_doc_0001_target   \n",
       "1  gold_doc_0001  gold_doc_0001_ctx_prev   \n",
       "2  gold_doc_0001  gold_doc_0001_ctx_next   \n",
       "3  gold_doc_0002    gold_doc_0002_target   \n",
       "4  gold_doc_0002  gold_doc_0002_ctx_prev   \n",
       "5  gold_doc_0002  gold_doc_0002_ctx_next   \n",
       "6  gold_doc_0003    gold_doc_0003_target   \n",
       "7  gold_doc_0003  gold_doc_0003_ctx_prev   \n",
       "8  gold_doc_0003  gold_doc_0003_ctx_next   \n",
       "9  gold_doc_0004    gold_doc_0004_target   \n",
       "\n",
       "                                                text  num_tokens  label  \\\n",
       "0   Souƒçasn√° √∫rove≈à spot≈ôeby energie je alarmuj√≠c√≠ .           7      1   \n",
       "1  Z√°soby zemn√≠ho plynu v evropsk√Ωch skladech dos...          10      0   \n",
       "2  Energetick√© spoleƒçnosti ozn√°mily stabiln√≠ dod√°...          10      0   \n",
       "3  Rozd√≠l mezi platy mu≈æ≈Ø a ≈æen z≈Øst√°v√° i na d√°le...          12      1   \n",
       "4  Pr≈Ømƒõrn√° mzda v ƒåesk√© republice ve t≈ôet√≠m ƒçtvr...          16      0   \n",
       "5  Statistici oƒçek√°vaj√≠ , ≈æe r≈Øst mezd zpomal√≠ v ...          11      0   \n",
       "6           Tempo v√Ωstavby nov√Ωch byt≈Ø je ≈æalostn√© .           7      1   \n",
       "7  V posledn√≠ch mƒõs√≠c√≠ch do≈°lo k v√Ωrazn√©mu pokles...          10      0   \n",
       "8  Developersk√© spoleƒçnosti pl√°nuj√≠ nav√Ω≈°it inves...           9      0   \n",
       "9     Kvalita poskytovan√Ωch slu≈æeb je v≈°ak tristn√≠ .           7      1   \n",
       "\n",
       "   is_context context_type  \n",
       "0       False         None  \n",
       "1        True         prev  \n",
       "2        True         next  \n",
       "3       False         None  \n",
       "4        True         prev  \n",
       "5        True         next  \n",
       "6       False         None  \n",
       "7        True         prev  \n",
       "8        True         next  \n",
       "9       False         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Embedding Information:\n",
      "  - CLS embedding shape: (768,)\n",
      "  - Mean embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä GOLD Sentence-Level Data Preview:\\n\")\n",
    "\n",
    "# Display without embedding columns (too long)\n",
    "display_cols = [col for col in sentence_df_gold.columns if 'embedding' not in col]\n",
    "display(sentence_df_gold[display_cols].head(10))\n",
    "\n",
    "print(\"\\nüìã Embedding Information:\")\n",
    "print(f\"  - CLS embedding shape: {sentence_df_gold['cls_embedding'].iloc[0].shape}\")\n",
    "print(f\"  - Mean embedding shape: {sentence_df_gold['mean_embedding'].iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gold_stats_header",
   "metadata": {},
   "source": [
    "### 4.2 Quick Statistics Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gold_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà GOLD Dataset Quick Stats:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Documents</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Sentences</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Target Sentences</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Context Sentences</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Tokens</td>\n",
       "      <td>17557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LJMPNIK Tokens</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Target Sentences:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>- Neutral (L0)</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>- LJMPNIK (L1)</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>- L0:L1 Ratio</td>\n",
       "      <td>0.57:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Metric   Count\n",
       "0         Total Documents     520\n",
       "1         Total Sentences    1560\n",
       "2      - Target Sentences     520\n",
       "3     - Context Sentences    1040\n",
       "4            Total Tokens   17557\n",
       "5          LJMPNIK Tokens     305\n",
       "6                                \n",
       "7       Target Sentences:        \n",
       "8          - Neutral (L0)     188\n",
       "9          - LJMPNIK (L1)     332\n",
       "10          - L0:L1 Ratio  0.57:1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data looks good!\n",
      "   Average 0.6 LJMPNIK words per document\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üìà GOLD Dataset Quick Stats:\\n\")\n",
    "\n",
    "# Filter to target sentences only\n",
    "target_sentences = sentence_df_gold[~sentence_df_gold.get('is_context', False)]\n",
    "\n",
    "stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Documents',\n",
    "        'Total Sentences',\n",
    "        '  - Target Sentences',\n",
    "        '  - Context Sentences',\n",
    "        'Total Tokens',\n",
    "        'LJMPNIK Tokens',\n",
    "        '',\n",
    "        'Target Sentences:',\n",
    "        '  - Neutral (L0)',\n",
    "        '  - LJMPNIK (L1)',\n",
    "        '  - L0:L1 Ratio'\n",
    "    ],\n",
    "    'Count': [\n",
    "        token_df_gold['document_id'].nunique(),\n",
    "        len(sentence_df_gold),\n",
    "        len(target_sentences),\n",
    "        len(sentence_df_gold) - len(target_sentences),\n",
    "        len(token_df_gold),\n",
    "        (token_df_gold['is_target'] == True).sum(),\n",
    "        '',\n",
    "        '',\n",
    "        (target_sentences['label'] == 0).sum(),\n",
    "        (target_sentences['label'] == 1).sum(),\n",
    "        f\"{(target_sentences['label'] == 0).sum() / (target_sentences['label'] == 1).sum():.2f}:1\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(stats)\n",
    "\n",
    "# Check if everything looks reasonable\n",
    "n_docs = token_df_gold['document_id'].nunique()\n",
    "n_ljmpnik = (token_df_gold['is_target'] == True).sum()\n",
    "\n",
    "if n_docs > 0 and n_ljmpnik > 0:\n",
    "    print(\"\\n‚úÖ Data looks good!\")\n",
    "    print(f\"   Average {n_ljmpnik / n_docs:.1f} LJMPNIK words per document\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Something might be wrong - check the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver_header",
   "metadata": {},
   "source": [
    "## 5. Process SILVER Dataset (Optional)\n",
    "\n",
    "**SILVER Dataset:** Larger, automatically generated data (~1900 documents).\n",
    "\n",
    "‚ö†Ô∏è **This takes MUCH longer** (~30-60 minutes).\n",
    "\n",
    "You can skip this if:\n",
    "- You only want to experiment with GOLD data\n",
    "- You don't have SILVER data yet\n",
    "- You want to test the pipeline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "process_silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:28:47,320 - INFO - üöÄ Starting full pipeline for SILVER dataset\n",
      "2026-02-22 19:28:47,322 - INFO - ‚úÖ Models loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Processing SILVER dataset...\n",
      "\n",
      "‚è∞ This will take 30-60 minutes!\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:28:47,338 - INFO - Loaded 1903 entries from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\raw\\SILVER_data_raw.jsonl\n",
      "Processing silver data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1903/1903 [04:36<00:00,  6.88it/s] \n",
      "2026-02-22 19:33:23,977 - INFO - ‚úÖ Processed silver:\n",
      "2026-02-22 19:33:23,978 - INFO -    - Token-level: 78991 rows\n",
      "2026-02-22 19:33:23,979 - INFO -    - Sentence-level: 5709 rows\n",
      "2026-02-22 19:33:43,231 - INFO - üíæ Saved processed data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "‚úÖ SILVER dataset processing complete!\n",
      "   Tokens: 78,991 rows\n",
      "   Sentences: 5,709 rows\n",
      "   Documents: 1,903 unique\n",
      "   LJMPNIK words: 918\n"
     ]
    }
   ],
   "source": [
    "# Set this to True to process SILVER data\n",
    "PROCESS_SILVER = True  # ‚ö†Ô∏è Change to True when ready\n",
    "\n",
    "if PROCESS_SILVER:\n",
    "    if config.PATH_SILVER_RAW.exists():\n",
    "        print(\"üöÄ Processing SILVER dataset...\\n\")\n",
    "        print(\"‚è∞ This will take 30-60 minutes!\\n\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        token_df_silver, sentence_df_silver = run_full_pipeline('silver')\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"\\n‚úÖ SILVER dataset processing complete!\")\n",
    "        print(f\"   Tokens: {len(token_df_silver):,} rows\")\n",
    "        print(f\"   Sentences: {len(sentence_df_silver):,} rows\")\n",
    "        print(f\"   Documents: {token_df_silver['document_id'].nunique():,} unique\")\n",
    "        print(f\"   LJMPNIK words: {(token_df_silver['is_target'] == True).sum():,}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  SILVER raw data not found. Skipping.\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping SILVER processing\")\n",
    "    print(\"   (Set PROCESS_SILVER=True above to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_header",
   "metadata": {},
   "source": [
    "## 6. Verify Processed Data\n",
    "\n",
    "Load the saved files to verify integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "verify",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying processed files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:33:44,463 - INFO - ‚úÖ Loaded 17557 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\processed\\gold_tokens.pkl\n",
      "2026-02-22 19:33:44,538 - INFO - ‚úÖ Loaded 1560 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\processed\\gold_sentences.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GOLD data verified (SHA256 checksums match):\n",
      "   Tokens: 17,557 rows\n",
      "   Sentences: 1,560 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 19:33:47,429 - INFO - ‚úÖ Loaded 78991 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\processed\\silver_tokens.pkl\n",
      "2026-02-22 19:33:47,683 - INFO - ‚úÖ Loaded 5709 rows from C:\\Users\\dobes\\Documents\\UniversityCodingProject_10-02-26\\ThesisCoding\\data\\processed\\silver_sentences.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SILVER data verified (SHA256 checksums match):\n",
      "   Tokens: 78,991 rows\n",
      "   Sentences: 5,709 rows\n"
     ]
    }
   ],
   "source": [
    "from load_preprocess_data import load_processed_data\n",
    "\n",
    "print(\"üîç Verifying processed files...\\n\")\n",
    "\n",
    "# Verify GOLD\n",
    "try:\n",
    "    gold_tokens_verify = load_processed_data('gold', level='token', verify_integrity=True)\n",
    "    gold_sentences_verify = load_processed_data('gold', level='sentence', verify_integrity=True)\n",
    "    print(f\"‚úÖ GOLD data verified (SHA256 checksums match):\")\n",
    "    print(f\"   Tokens: {len(gold_tokens_verify):,} rows\")\n",
    "    print(f\"   Sentences: {len(gold_sentences_verify):,} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GOLD verification failed: {e}\")\n",
    "\n",
    "# Verify SILVER (if processed)\n",
    "if PROCESS_SILVER:\n",
    "    try:\n",
    "        silver_tokens_verify = load_processed_data('silver', level='token', verify_integrity=True)\n",
    "        silver_sentences_verify = load_processed_data('silver', level='sentence', verify_integrity=True)\n",
    "        print(f\"\\n‚úÖ SILVER data verified (SHA256 checksums match):\")\n",
    "        print(f\"   Tokens: {len(silver_tokens_verify):,} rows\")\n",
    "        print(f\"   Sentences: {len(silver_sentences_verify):,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SILVER verification failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### What You've Created\n",
    "\n",
    "‚úÖ **Processed data files** in `data/processed/` directory  \n",
    "‚úÖ **Integrity checksums** for all files (SHA256)  \n",
    "‚úÖ **Document IDs** auto-generated and tracked  \n",
    "‚úÖ **Independent embeddings** (no data leakage!)  \n",
    "‚úÖ **Full metadata** for qualitative analysis  \n",
    "\n",
    "### File Structure\n",
    "\n",
    "**Token-level DataFrame columns:**\n",
    "- `document_id` - Groups sentences from same document\n",
    "- `sentence_id` - Unique sentence identifier\n",
    "- `token_id` - Unique token identifier\n",
    "- `position` - Position in sentence\n",
    "- `form` - The actual word\n",
    "- `lemma` - Base form\n",
    "- `pos` - Part of speech tag\n",
    "- `embedding` - 768-dim BERT vector\n",
    "- `is_target` - True if this is the LJMPNIK word\n",
    "- `label` - Sentence-level label (0=neutral, 1=contains LJMPNIK)\n",
    "- `token_label` - Token-level label (0=neutral, 1=LJMPNIK)\n",
    "\n",
    "**Sentence-level DataFrame columns:**\n",
    "- `document_id` - Document identifier\n",
    "- `sentence_id` - Unique sentence identifier\n",
    "- `text` - Original sentence text\n",
    "- `num_tokens` - Token count\n",
    "- `cls_embedding` - BERT [CLS] token (768-dim)\n",
    "- `mean_embedding` - Mean of token embeddings (768-dim)\n",
    "- `label` - 0 (neutral) or 1 (contains LJMPNIK)\n",
    "- `is_context` - True for context sentences\n",
    "- `context_type` - 'prev', 'next', or None\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Run `02_EDA.ipynb`** to explore the data\n",
    "2. **Run experiment notebooks** (M1, M2) for modeling\n",
    "3. **Don't re-run this notebook** unless:\n",
    "   - Raw data changes\n",
    "   - You need to regenerate embeddings\n",
    "   - You suspect data corruption\n",
    "\n",
    "### File Locations\n",
    "\n",
    "```\n",
    "data/\n",
    "‚îú‚îÄ‚îÄ raw/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ GOLD_data_raw.jsonl           # Your input\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ SILVER_data_raw.jsonl\n",
    "‚îî‚îÄ‚îÄ processed/\n",
    "    ‚îú‚îÄ‚îÄ gold_tokens.pkl               # Generated by this notebook ‚úÖ\n",
    "    ‚îú‚îÄ‚îÄ gold_tokens.pkl.sha256        # Integrity check ‚úÖ\n",
    "    ‚îú‚îÄ‚îÄ gold_sentences.pkl            # Generated by this notebook ‚úÖ\n",
    "    ‚îú‚îÄ‚îÄ gold_sentences.pkl.sha256     # Integrity check ‚úÖ\n",
    "    ‚îú‚îÄ‚îÄ silver_tokens.pkl             # (if PROCESS_SILVER=True)\n",
    "    ‚îú‚îÄ‚îÄ silver_tokens.pkl.sha256\n",
    "    ‚îú‚îÄ‚îÄ silver_sentences.pkl\n",
    "    ‚îî‚îÄ‚îÄ silver_sentences.pkl.sha256\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Processing complete! üéâ**\n",
    "\n",
    "**Time to run EDA:** Open `02_EDA.ipynb` next!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
