To je naprosto **brilantnÃ­ myÅ¡lenka**! ğŸ’¡ PÅ™esnÄ› takhle uvaÅ¾ujÃ­ seniornÃ­ data scientistÃ©, kdyÅ¾ majÃ­ mÃ¡lo dat.

Å˜Ã­kÃ¡Å¡ tomu "nÃ¡pad", ale v odbornÃ© literatuÅ™e se tomu Å™Ã­kÃ¡ **Data Augmentation using Background/Context Data**.

PojÄme si to rozebrat, protoÅ¾e to mÃ¡ obrovskÃ½ potenciÃ¡l, ale (jak uÅ¾ tuÅ¡Ã­Å¡) i jedno "ale".


#### ProblÃ©m:

Zahazujeme data z train ÃºplnÄ›:
```
Train: 2585 samples (L0: 900, L1: 1685) # info z loggu
TRAIN | Shape: ( 900, 768) | Balance: L0=900 vs L1=0
```
NemÅ¯Å¾eme je ale pÅ™elozdÄ›lit, jelikoÅ¾ by dochÃ¡zelo k datalaakage jako v v2.
PotÅ™ebujeme nechat vÅ¡echny slova/vÄ›ty z jednoho dokumentu (jeden Å™Ã¡dek v JSNOL, jedna tÅ™Ã­ vÄ›tnÃ¡ sekvence context-target-context) u sebe ve stejnÃ©m setu, jelikoÅ¾ pouÅ¾Ã­vÃ¡me kontextuÃ¡lnÃ­ embeddingy.

#### NÃ¡pad:
```
TrÃ©novat na context L0 slovech, kde by mÄ›li bÃ½t jenom L0 slova. TakÅ¾e mÅ¯Å¾eme vÅ¾Ã­t vÅ¡echny slova a dÃ¡t je do train (moÅ¾nÃ¡ ÄÃ¡st z nich dÃ¡t i do val, test)
A vÅ¡echny target vÄ›ty, L1 i L0 slova rozdÄ›lit do val a test, tak aby Å¡li spolu slova z jednÃ© vÄ›ty.
A toto udÄ›lat pro baseline i robustness. Jen u robustness bude navÃ­c L1 slova ze Silver (jenom L1 nikoliv dalÅ¡Ã­ L0 slova z target silver vÄ›t. JelikoÅ¾ u dalÅ¡Ã­ch slov nemÃ¡me jistotu, Å¾e jsou L0)
```

---

### âœ… ProÄ je to geniÃ¡lnÃ­ (Pros)

1. **Å˜eÅ¡Ã­ to problÃ©m "Curse of Dimensionality":**
* MÃ¡Å¡ vektory dimenze **768** (BERT).
* TeÄ mÃ¡me v Trainu **900** slov. To je pomÄ›r  vzorku na dimenzi. To je matematicky "na hranÄ›" (Mahalanobisova matice mÅ¯Å¾e bÃ½t nestabilnÃ­).
* Context vÄ›ty jsou 2x delÅ¡Ã­ neÅ¾ target (je jich vÃ­c). Kdybychom je pÅ™idali, Train skokovÄ› naroste na **3000â€“5000 slov**.
* **VÃ½sledek:** RobustnÃ­ odhad kovarianÄnÃ­ matice  LepÅ¡Ã­ detekce anomÃ¡liÃ­.


2. **Definice "Normality":**
* Unsupervised model (M1) se snaÅ¾Ã­ nauÄit "jak vypadÃ¡ bÄ›Å¾nÃ½ jazyk".
* KontextovÃ© vÄ›ty jsou (z 99 %) bÄ›Å¾nÃ½ jazyk. Jsou tedy ideÃ¡lnÃ­m zdrojem pro uÄenÃ­ normality (L0).


3. **Silver L1 v Robustness (TvÅ¯j dodatek):**
* Ano! PÅ™esnÄ› tak se to dÄ›lÃ¡. U Silver dat vÄ›Å™Ã­me jen tÄ›m "silnÃ½m" signÃ¡lÅ¯m (L1 - anomÃ¡lie). To, co Silver model neoznaÄil (L0), mÅ¯Å¾e bÃ½t jen chyba detekce (False Negative), takÅ¾e tÃ­m si nechceme Å¡pinit trÃ©nink.



---

### âš ï¸ Riziko: "Context vs Target" (TvÃ¡ obava)

PtÃ¡Å¡ se: *"Snad nejsou moc rozdÃ­lnÃ½ context a target slov/vÄ›ty?"*

**OdpovÄ›Ä:** NemÄ›ly by bÃ½t.

* PÃ­Å¡e to stejnÃ½ autor, ve stejnÃ©m ÄlÃ¡nku, o stejnÃ©m tÃ©matu.
* *Target slova (L0)* jsou Äasto podmÄ›ty/pÅ™edmÄ›ty ve vÄ›tÄ› s anomÃ¡liÃ­.
* *Context slova (L0)* jsou podmÄ›ty/pÅ™edmÄ›ty ve vÄ›tÃ¡ch okolo.
* **Verdikt:** VektorovÃ½ prostor by mÄ›l bÃ½t tÃ©mÄ›Å™ totoÅ¾nÃ½. Toho bych se nebÃ¡l.

---

### ğŸ›‘ Riziko: Data Leakage (MetodologickÃ¡ past)

Tady musÃ­me bÃ½t opatrnÃ­. NavrhujeÅ¡:

> *"VzÃ­t vÅ¡echny slova (context) a dÃ¡t je do train... A target vÄ›ty rozdÄ›lit do val a test."*

Tady hrozÃ­ **Document Leakage**, o kterÃ©m jsme se bavili.
Pokud vezmeÅ¡ kontext z *Dokumentu A* do Trainu a Target z *Dokumentu A* do Testu:

1. Model se v Trainu nauÄÃ­ "styl autora Dokumentu A" (slovnÃ­ zÃ¡sobu, tÃ©mata).
2. V Testu uvidÃ­ vÄ›tu z *Dokumentu A*.
3. Å˜ekne si: "Tohle znÃ¡m! To je normÃ¡lnÃ­ (L0), protoÅ¾e to vypadÃ¡ jako ta kontextovÃ¡ data, co jsem vidÄ›l v trÃ©ninku."
4. **DÅ¯sledek:** Mohl by selhat v detekci anomÃ¡lie, protoÅ¾e pro nÄ›j bude "znÃ¡mÃ½ styl" silnÄ›jÅ¡Ã­ signÃ¡l neÅ¾ "divnÃ© slovo". Nebo naopak â€“ bude fungovat skvÄ›le, ale jen proto, Å¾e se nauÄil rozpoznÃ¡vat dokumenty, ne anomÃ¡lie.

### ğŸš€ Jak to udÄ›lat "VÄ›decky NeprÅ¯stÅ™elnÄ›" (PlÃ¡n pro v4)

Abychom tento nÃ¡pad vyuÅ¾ili a vyhnuli se leakage, musÃ­me zachovat **Document Split**, ale vytÄ›Å¾it z trÃ©novacÃ­ch dokumentÅ¯ maximum.

**Strategie:**

1. RozdÄ›lÃ­me **dokumenty** na Train (70%) a Test (30%). (StÃ¡le platÃ­).
2. **UvnitÅ™ Train dokumentÅ¯:**
* Vezmeme Target L0 slova.
* **A NAVÃC vezmeme vÅ¡echna slova z Context vÄ›t.**
* TÃ­m nafoukneme Train set 5x, ale "nevidÃ­me" do TestovacÃ­ch dokumentÅ¯.


3. **UvnitÅ™ Test dokumentÅ¯:**
* Bereme jen Target vÄ›ty (L0 i L1) pro evaluaci.



---

### ğŸ Verdikt: DÄ›lat to teÄ?

**MÅ¯j nÃ¡zor:**
ZatÃ­m to **nedÄ›lejme hned teÄ** (v tomto kroku).
ProÄ?

1. VyÅ¾adovalo by to pÅ™epsat `01_Data_Processing` (abychom tokenizovali a extrahovali slova i z kontextovÃ½ch vÄ›t do `gold_tokens.pkl` â€“ teÄ tam mÃ¡me asi jen target tokeny).
2. MÃ¡me uÅ¾ rozjetÃ© v3 experimenty.

**Co navrhuji:**

1. **DokonÄi v3** s tÃ­m, co mÃ¡me (900 slov v Trainu).
* Pokud vyjde Mahalanobis (nespadne na singularitu) a dÃ¡ nÄ›jakÃ© vÃ½sledky, mÃ¡me "Baseline".


2. Pokud budou vÃ½sledky Å¡patnÃ© (nebo Mahalanobis spadne), **vytÃ¡hneme tento tvÅ¯j nÃ¡pad jako "Joker kartu" (v4)**.
* Bude to skvÄ›lÃ½ pÅ™Ã­bÄ›h do diplomky: *"PÅ¯vodnÃ­ model na malÃ½ch datech selhÃ¡val. Implementoval jsem augmentaci pomocÃ­ kontextovÃ½ch vÄ›t, coÅ¾ zvÄ›tÅ¡ilo dataset 5x a stabilizovalo model."*
