# Struktura experimentÅ¯

### Filtrace
* **`filter_type`:**
    * `'aggressive'` (Jen NOUN, ADJ, VERB, ADV)
    * `'mild'` (VÅ¡e kromÄ› ADP, CONJ, PUNCT, SYM)
    * `'none'` (VÅ¡echny tokeny)

### Reprezentace vÄ›ty 
* **`pooling_method`:**
    * `'mean'` (PrÅ¯mÄ›r embeddingÅ¯ tokenÅ¯)
    * `'cls'` (Embedding speciÃ¡lnÃ­ho [CLS] tokenu)

### Datasety
1.  **I - MalÃ½ ÄistÃ½ dataset** $\rightarrow$ **`GOLD` Dataset**
    * RuÄnÄ› anotovanÃ½, kotrolovanÃ½, vysokÃ¡ kvalita, dÅ¯vÄ›ryhodnÃ½ pro testovÃ¡nÃ­. Kombinace REAL, LLM, AUTHOR.
2.  **II - VelkÃ½ dataset** $\rightarrow$ **`SILVER` Dataset**
    * Automaticky generovanÃ½, vÃ½znamnÄ› vÄ›tÅ¡Ã­, ale mÅ¯Å¾e obsahovat Å¡um (nenÃ­ 100% perfektnÃ­), "weakly labeled" data.
3.  **III - HybridnÃ­ dataset** $\rightarrow$ **`HYBRID` Dataset**
    * Kombinuje anomÃ¡lie ze SILVER a GOLD a neutralitu z GOLD.

---
KaÅ¾dÃ½ nÃ­Å¾e uvedenÃ½ experiment se provÃ¡dÃ­ v kombinacÃ­ch:
`'aggressive'` vs `'mild'` vs `'none'`

### **---> M1: Unsupervised Outlier Detection**
*CÃ­l: ModelovÃ¡nÃ­ normality. TrÃ©nujeme pouze na neutrÃ¡lnÃ­ tÅ™Ã­dÄ› (L0).

* **S1 - Token Level (Slova)**
* *PoznÃ¡mka:* PoÄÃ­tÃ¡me zÃ¡vilost F1 na parametrech/tresholdech: *nu*, *contamination*, *p-value*
* *PoznÃ¡mka:* *`'Gold Baseline'`:** TrÃ©nink na GOLD L0, test na GOLD L1+L0. * `'Combined Robustness'`:** TrÃ©nink na GOLD L0, test na GOLD+SILVER L1 a GOLD L0.

    * **S1a - ONSVM (One-Class SVM):** GeometrickÃ¡ metoda pro nelineÃ¡rnÃ­ hranice.
        * **S1a-I (Gold Baseline)** 
        * **S1a-II (Combined Robustness)**
    * **S1b - Isolation Forest (IF):** StromovÃ¡ metoda izolujÃ­cÃ­ odlehlÃ© body.
        * **S1b-I (Gold Baseline)** 
        * **S1b-II (Combined Robustness)** 
    * **S1c - Mahalanobis Distance (MD):** StatistickÃ¡ metoda (vzdÃ¡lenost od centroidu distribuce).
        * **S1c-I (Gold Baseline)**
        * **S1c-II (Combined Robustness)**
* *OtÃ¡zka:* Na trÃ©novat nejlepÅ¡Ã­ model znovu na augmentovanÃ©m datasetuâ€¦ L1 z Gold a Silver, L0 z target Gold a z Gold kontextovÃ½ch vÄ›t

* **S2 - Sentence Level (VÄ›ty)**
    * *PoznÃ¡mka:* U vÅ¡ech S2 experimentÅ¯ navÃ­c porovnÃ¡vÃ¡me vliv reprezentace vÄ›ty (**Mean Pooling** vs **[CLS] Token**).
    * *PoznÃ¡mka:* PoÄÃ­tÃ¡me zÃ¡vilost F1 na parametrech/tresholdech: *nu*, *contamination*, *p-value*
    * **S2a - ONSVM (VÄ›ty):** Klasifikace celÃ½ch vÄ›t jako anomÃ¡liÃ­.
        * **S2a-I (Gold Baseline)**
        * **S2a-II (Combined Robustness)**
    * **S2b - Isolation Forest (VÄ›ty):**
        * **S2b-I (Gold Baseline)** 
        * **S2b-II (Combined Robustness)** 
    * **S2c - Mahalanobis Distance (VÄ›ty):**
        * **S2c-I (Gold Baseline)** 
        * **S2c-II (Combined Robustness)**
 
### **---> M2: Supervised Classification**

* **S1 - Token Level (Slova)**
    * **S1a - Baseline (Imbalanced):** VÅ¡echna data, nev    yvÃ¡Å¾enÃ©.
    * **S1b - Gold Balanced:** Undersampling L0 z Gold datasetu.
    * **S1c - Bootstrap Validation:** OvÄ›Å™enÃ­ stability S1b (100 iteracÃ­).
    * **S1d - Train Noisy, Test Clean:** TrÃ©nink na Silver, Test na Gold.
    * **S1e - Hybrid:** Max L1 (Gold+Silver) + Clean Balanced L0 (Gold).

* **S2 - Sentence Level (VÄ›ty)**
* *PoznÃ¡mka:* U vÅ¡ech S2 experimentÅ¯ navÃ­c porovnÃ¡vÃ¡me vliv reprezentace vÄ›ty (**Mean Pooling** vs **[CLS] Token**).
    * **S2a - Gold Balanced:** TrÃ©nink na vÄ›tÃ¡ch z malÃ©ho datasetu.
    * **S2b - Hybrid:** TrÃ©nink na L1 vÄ›tÃ¡ch (GOLD + SILVER) + L0 vÄ›tÃ¡ch (Gold).
  

### --> M3 (LLM)
* **S1 - Token Level**
* **S2 - Sentence Level**

### --> M4 (NN):
* **S1 - Token Level**
* **S2 - Sentence Level**
  
### --> Kombinace pro praxi (prvnÄ› poznat vÄ›tu, pak konkrÃ©tnÃ­ LJMPNIK)


---
---

## Struktura projektu

```text
diploma_thesis_project/
â”‚
â”œâ”€â”€ data/                   # (V .gitignore, na GitHub se nedÃ¡vÃ¡)
â”‚   â”œâ”€â”€ raw/                # PÅ¯vodnÃ­ JSONL
|   â”œâ”€â”€ interim/            # ZprocesovanÃ© JSONL s embed. a postagy pro lepÅ¡Ã­ ÄtenÃ­ a prochÃ¡zenÃ­.
â”‚   â””â”€â”€ vectors/            # ZpracovanÃ© .pkl
â”‚
â”œâ”€â”€ src/  
|   â”œâ”€â”€ src_servis/                 # pomocnÃ© skripty 
â”‚       â”œâ”€â”€ check_models.py
â”‚       â”œâ”€â”€ data_generate.py        # GenerÃ¡tor SILVER datasetu      
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           		# Konstanty, cesty, palety
â”‚   â”œâ”€â”€ load_preprocess_data.py	    # NaÄÃ­tÃ¡nÃ­ a preprocessing textu (embeddingy, postagy, tokenizaceâ€¦)
â”‚   â”œâ”€â”€ evaluation.py       		# Metriky, PR Curve, Bootstrap (zatÃ­m nemÃ¡m!!)
â”‚   â””â”€â”€ visualization.py    		# UnifikovanÃ© funkce pro grafy (zatÃ­m nemÃ¡m!!)
â”‚
â”œâ”€â”€ notebooks/              
â”‚   â”œâ”€â”€ 01_EDA_preprocess.ipynb
â”‚   â”œâ”€â”€ 02_M1_S1_Unsupervised_Detection-Token_level.ipynb
â”‚   â”œâ”€â”€ 03_M1_S2_Unsupervised_Detection-Senc_level.ipynb
â”‚   â”œâ”€â”€ 04_M2_S1_Supervised_Classification-Token_level.ipynb
â”‚   â”œâ”€â”€ 05_M2_S1_Supervised_Classification-Token_level.ipynb
â”‚
â”œâ”€â”€ requirements.txt        # Seznam knihoven (pip freeze)
â”œâ”€â”€ README.md               # Popis projektu, jak to spustit
â””â”€â”€ venv      
```

* MoÅ¾nÃ¡ Äasem pÅ™idat `â””â”€â”€ main.py   # (VolitelnÃ©) Jeden skript, kterÃ½ by to pustil celÃ© narÃ¡z`
 
---
---

#ğŸ“‚ 1. Logika Dat a SouborÅ¯:

1. **RAW JSONL** jsou nedotknutelnÃ© archivy.
2. **PKL Artefakty** jsou "cihly" (vektory), kterÃ© si pÅ™edpÅ™ipravÃ­me (jednou).
3. **TrÃ©novacÃ­ sety (Hybrid)** se stavÃ­ **"on-the-fly"** v pamÄ›ti spojovÃ¡nÃ­m cihel.

###AdresÃ¡Å™ovÃ¡ struktura dat (`data/`)* `data/raw/` -> `dataset_gold.jsonl`, `dataset_silver.jsonl`
* `data/vectors/gold/` -> `gold_token_mild_l0.pkl`, `gold_sent_mean_l1.pkl`, ...
* `data/vectors/silver/` -> `silver_token_mild_l1.pkl`, ...

---

#ğŸ 2. Obsah sloÅ¾ky `src/` (Python Moduly)Toto je tvÃ¡ knihovna. Notebooky budou volat funkce odsud.

###A. `src/config.py` (Mozek)* **Cesty:** DefinovanÃ© pÅ™es `pathlib` (BASE_DIR, DATA_DIR, VECTORS_DIR).
* **Model:** `ufal/robeczech-base`, `MAX_LENGTH`.
* **Filtry (Sety):**
* `POS_ALLOWED_AGGRESSIVE = {'NOUN', 'ADJ', ...}`
* `POS_FORBIDDEN_MILD = {'ADP', 'PUNCT', ...}`


* **Barvy (Design):**
* `COLORS`: Dictionary s hex kÃ³dy (Pastel pro tÅ™Ã­dy, Coolwarm pro heatmapy).
* `L0 = Blue`, `L1 = Red`.


* **Konstanty:** `RANDOM_SEED = 42`.

###B. `src/load_preprocess_data.py` (Motor)Tento soubor bude mÃ­t dvÄ› hlavnÃ­ ÄÃ¡sti:

1. **Pipeline pro generovÃ¡nÃ­ artefaktÅ¯ (spouÅ¡tÃ­ se v 01_EDA):**
* Fce `process_jsonl_to_pkl(input_path, dataset_name)`:
* NaÄte JSONL.
* SpustÃ­ BERT a spaCy.
* Aplikuje filtry (loop pÅ™es none/mild/agg).
* UloÅ¾Ã­ `.pkl` soubory do `data/vectors/`.
* **DÅ¯leÅ¾itÃ©:** UklÃ¡dÃ¡ zvlÃ¡Å¡Å¥ L0 a L1. UklÃ¡dÃ¡ zvlÃ¡Å¡Å¥ Tokeny a VÄ›ty (Mean/CLS).


2. **DataLoader pro experimenty (spouÅ¡tÃ­ se v M1/M2):**
* Fce `load_data(strategy, level, filter_type, pooling=None)`:
* Pokud `strategy == 'GOLD_BASELINE'`: NaÄte jen Gold `.pkl`.
* Pokud `strategy == 'HYBRID'`: NaÄte Gold `.pkl` + Silver `.pkl` a spojÃ­ je (`np.concatenate`).
* VracÃ­ hotovÃ© `X_train`, `X_test`, `y_train`, `y_test` pÅ™ipravenÃ© pro `model.fit()`.


###C. `src/evaluation.py` (RozhodÄÃ­)* Fce `calculate_metrics(y_true, y_pred)`: VracÃ­ prec, rec, f1.
* Fce `find_optimal_threshold(y_true, anomaly_scores)`:
* Pro M1 (Unsupervised).
* Projede PR kÅ™ivku a najde threshold s nejvyÅ¡Å¡Ã­m F1.


* Fce `bootstrap_evaluation(model, X, y)`: Pro M2/S1c.

###D. `src/visualization.py` (MalÃ­Å™)* Fce `setup_style()`: NastavÃ­ Seaborn theme a paletu z configu.
* Fce `plot_pr_curve()`: VykreslÃ­ kÅ™ivku a bod optima.
* Fce `plot_confusion_matrix()`: Heatmapa s `coolwarm` (nebo Blues/Reds).
* Fce `plot_metric_dependency()`: Pro zÃ¡vislost F1 na parametrech (contamination/nu).

---

#ğŸ““ 3. Struktura NotebookÅ¯ (Experimenty)Notebooky budou ÄistÃ©, s minimem kÃ³du a maximem Markdownu (pÅ™Ã­bÄ›h).

###`01_EDA_preprocess.ipynb`* **ÃšÄel:** PÅ™Ã­prava pÅ¯dy.
* **Akce:**
1. Import `src.load_preprocess_data`.
2. SpustÃ­ generovÃ¡nÃ­ vektorÅ¯ pro GOLD i SILVER.
3. **EDA:** VykreslÃ­ poÄty slov, histogramy dÃ©lek vÄ›t, pomÄ›ry tÅ™Ã­d (pouÅ¾ije `src.visualization`).
4. 


###`02_M1_Unsupervised_Detection.ipynb` (Sjednoceno Token & Sent)* **ÃšÄel:** Experimenty M1 (S1 i S2).
* **Struktura kÃ³du:**
* Loop pÅ™es **Level** (`Token`, `Sentence`).
* Loop pÅ™es **Algo** (`ONSVM`, `IF`, `MD`).
* Loop pÅ™es **Filter** (`Agg`, `Mild`, `None`).
* **Exp 1 (Baseline):** Train Gold L0 -> Test Gold Mix.
* **Exp 2 (Robustness):** Train Gold L0 -> Test Hybrid Mix.
* *VÃ½poÄet:* HledÃ¡nÃ­ optimÃ¡lnÃ­ho `p-value` / `nu`.
* *Vizualizace:* PR KÅ™ivka.
* 

###`03_M2_Supervised_Classification.ipynb` (Sjednoceno Token & Sent)* **ÃšÄel:** Experimenty M2.
* **Struktura kÃ³du:**
* **ÄŒÃ¡st S1 (Tokeny):**
* S1a (Baseline) -> S1b (Balanced) -> S1c (Bootstrap) -> S1d (Noisy Train) -> **S1e (Hybrid Master)**.


* **ÄŒÃ¡st S2 (VÄ›ty):**
* SrovnÃ¡nÃ­ `Mean` vs `CLS`.
* S2a (Gold Balanced) -> S2b (Hybrid Master).





---

#ğŸ›  4. ImplementaÄnÃ­ "Cheat Sheet"Tady je nÃ¡vod, co teÄ udÄ›lat krok za krokem:

1. **VytvoÅ™ sloÅ¾ky:** `src`, `data/raw`, `data/vectors`.
2. **VytvoÅ™ `src/config.py`:** Definuj tam cesty a barviÄky.
3. **VytvoÅ™ `src/load_preprocess_data.py`:**
* ZkopÃ­ruj tam logiku z naÅ¡eho poslednÃ­ho chatu (BERT + uklÃ¡dÃ¡nÃ­ PKL).
* DopiÅ¡ funkci `get_data_for_experiment(...)`, kterÃ¡ bude umÄ›t spojit Gold a Silver vektory.


4. **SpusÅ¥ `01_EDA_preprocess.ipynb`:** Nech to chroustat (vytvoÅ™Ã­ to `.pkl` soubory).
5. **VytvoÅ™ `src/visualization.py`:** Aby grafy v dalÅ¡Ã­ch noteboocÃ­ch vypadaly stejnÄ›.
6. **ZaÄni experimentovat v `02_M1...`:** TeÄ uÅ¾ jen importujeÅ¡ `get_data_for_experiment`, zavolÃ¡Å¡ model a kreslÃ­Å¡ grafy.

Tato struktura je **modulÃ¡rnÃ­**. AÅ¾ budeÅ¡ dÄ›lat M3 (LLM), jen pÅ™idÃ¡Å¡ `04_M3_LLM.ipynb` a vyuÅ¾ijeÅ¡ stejnÃ¡ data a stejnÃ© vizualizace.
